{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 14906946,
          "datasetId": 9474986,
          "databundleVersionId": 15772239
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "name": "Cardiotoxicity",
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarthak-Chauhan-Git/Drug-induced-cardiotoxicity-classification-model/blob/main/Cardiotoxicity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "sarthakchauhanml_smiles_dataset_with_fingerprints_rdkit_images_path = kagglehub.dataset_download('sarthakchauhanml/smiles-dataset-with-fingerprints-rdkit-images')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "bh5fB--shi6G"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "sarthakchauhanml_smiles_dataset_with_fingerprints_rdkit_images_path = kagglehub.dataset_download('sarthakchauhanml/smiles-dataset-with-fingerprints-rdkit-images')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "w5wKvU-fBBGm",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:26:16.011592Z",
          "iopub.execute_input": "2026-02-25T05:26:16.012246Z",
          "iopub.status.idle": "2026-02-25T05:26:16.770485Z",
          "shell.execute_reply.started": "2026-02-25T05:26:16.012218Z",
          "shell.execute_reply": "2026-02-25T05:26:16.769828Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ«€ Cardiotoxicity Classification with Multi-Modal Deep Learning\n",
        "\n",
        "> **Objective:** Predict whether a chemical compound is cardiotoxic (hERG channel blocker) by fusing two complementary molecular representations â€” SMILES strings and pre-computed molecular descriptors â€” through a cross-attention gated deep learning architecture.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Architecture Overview\n",
        "\n",
        "```\n",
        "SMILES  â”€â”€â–º Embedding â”€â”€â–º 1D-CNN â”€â”€â–º AdaptiveMaxPool â”€â”€â–º FC(128) â”€â”€â–º f_s\n",
        "                                                                         \\\n",
        "                                                            Cross-Attn + Gate â”€â”€â–º FC(64) â”€â”€â–º Sigmoid\n",
        "                                                                         /\n",
        "FP desc â”€â”€â–º FC(256) â”€â”€â–º FC(128) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º f_f\n",
        "```\n",
        "\n",
        "| Branch | Input | Output |\n",
        "|---|---|---|\n",
        "| SMILES Encoder | Character-tokenised sequence | 128-dim vector `f_s` |\n",
        "| Fingerprint Encoder | LASSO-selected descriptors | 128-dim vector `f_f` |\n",
        "| Fusion | Cross-attention + softmax gating | 128-dim fused vector |\n",
        "| Classifier | Fused vector | Cardiotoxicity probability |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‚ Dataset\n",
        "- **SMILES files** (`train_validation_pipe1.csv`, `external_test_set_*.csv`) â€” columns: `SMILES`, `ACTIVITY`\n",
        "- **Descriptor files** (`cardiotrain*_merged.csv`, `cardiotest*_merged.csv`) â€” columns: `Smiles` + ~1800 molecular descriptors\n"
      ],
      "metadata": {
        "id": "500b67d6-e616-4112-b4b8-28ad5bb4f565"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Â· Setup â€” Imports & Reproducibility"
      ],
      "metadata": {
        "id": "6bc31e11-8ba5-4fd3-bd74-bf0dedb50987"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install xgboost --quiet\n",
        "\n",
        "import os, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, f1_score, accuracy_score, matthews_corrcoef,\n",
        "    roc_curve, precision_recall_curve, auc, confusion_matrix,\n",
        "    average_precision_score,\n",
        ")\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import xgboost as xgb\n",
        "import shap\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# â”€â”€ Reproducibility â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"[INFO] Using device: {DEVICE}\")\n",
        "\n",
        "OUTPUT_DIR = \"outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"[INFO] Outputs will be saved to: {OUTPUT_DIR}/\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:26:16.771647Z",
          "iopub.execute_input": "2026-02-25T05:26:16.771956Z",
          "iopub.status.idle": "2026-02-25T05:26:29.126657Z",
          "shell.execute_reply.started": "2026-02-25T05:26:16.771933Z",
          "shell.execute_reply": "2026-02-25T05:26:29.125824Z"
        },
        "id": "ae3d617a-69d9-48f5-9372-65c8c6f0ed5e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Â· Configuration â€” File Paths & Hyperparameters\n",
        "\n",
        "Update the paths below to point to your dataset files.\n",
        "\n",
        "| Variable | Description |\n",
        "|---|---|\n",
        "| `SMILES_*` | CSV with `SMILES` + `ACTIVITY` columns |\n",
        "| `FP_*` | CSV with `Smiles` + descriptor feature columns |\n",
        "| `MAX_LEN` | Maximum SMILES sequence length for padding |\n",
        "| `BATCH_SIZE` | Mini-batch size for training |\n",
        "| `N_EPOCHS` | Maximum training epochs (early stopping applies) |\n"
      ],
      "metadata": {
        "id": "fbe1d473-0756-4d19-b3e1-df45a22264e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Kaggle / local paths â€” update as needed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "BASE = \"/kaggle/input/datasets/sarthakchauhanml/smiles-dataset-with-fingerprints-rdkit-images/Paper_data\"\n",
        "\n",
        "SMILES_TRAIN = f\"{BASE}/labeled_data/train/train_validation_pipe1.csv\"\n",
        "SMILES_TEST1 = f\"{BASE}/labeled_data/test/external_test_set_neg.csv\"\n",
        "SMILES_TEST2 = f\"{BASE}/labeled_data/test/external_test_set_new.csv\"\n",
        "SMILES_TEST3 = f\"{BASE}/labeled_data/test/external_test_set_pos.csv\"\n",
        "\n",
        "FP_TRAIN = f\"{BASE}/pipeline1_features/train/cardiotrainall_merged.csv\"\n",
        "FP_TEST1 = f\"{BASE}/pipeline1_features/test/cardiotestnegall_merged.csv\"\n",
        "FP_TEST2 = f\"{BASE}/pipeline1_features/test/cardiotestnewall_merged.csv\"\n",
        "FP_TEST3 = f\"{BASE}/pipeline1_features/test/cardiotestposall_merged.csv\"\n",
        "\n",
        "# â”€â”€ Hyperparameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "BATCH_SIZE = 64\n",
        "MAX_LEN    = 120     # SMILES sequence pad/truncate length\n",
        "N_EPOCHS   = 50      # max epochs (early stopping will trigger sooner)\n",
        "N_HEADS    = 4       # attention heads in cross-attention module\n",
        "PATIENCE   = 7       # early stopping patience\n",
        "LR         = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "print(\"[CONFIG] Settings loaded.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:26:29.127715Z",
          "iopub.execute_input": "2026-02-25T05:26:29.128538Z",
          "iopub.status.idle": "2026-02-25T05:26:29.134034Z",
          "shell.execute_reply.started": "2026-02-25T05:26:29.128501Z",
          "shell.execute_reply": "2026-02-25T05:26:29.133452Z"
        },
        "id": "280f3734-3cc5-442a-bc62-6bbfd43aaf57"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Â· Data Loading & Preprocessing\n",
        "\n",
        "### Strategy\n",
        "The SMILES files and fingerprint descriptor files are loaded separately and then **aligned by row index** (they correspond 1-to-1). This is necessary because the fingerprint files may use a different SMILES column name (`Smiles` vs `SMILES`) or may lack a SMILES column altogether.\n",
        "\n",
        "Labels are taken from the SMILES file (`ACTIVITY` column, renamed to `Label`) and attached to the fingerprint data by positional alignment.\n",
        "\n",
        "**Data flow:**\n",
        "```\n",
        "SMILES file  â†’  SMILES sequences + Label\n",
        "FP file      â†’  descriptor matrix (aligned by row) + Label\n",
        "```\n"
      ],
      "metadata": {
        "id": "dd832d7a-dc90-4a76-92f7-ce208660ce00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Helper: detect the SMILES column (handles case variations) â”€â”€â”€â”€\n",
        "def find_smiles_col(df):\n",
        "    \"\"\"Return the SMILES column name regardless of case.\"\"\"\n",
        "    for c in df.columns:\n",
        "        if c.strip().upper() == \"SMILES\":\n",
        "            return c\n",
        "    raise ValueError(f\"No SMILES column found. Columns: {list(df.columns[:10])}\")\n",
        "\n",
        "\n",
        "def find_label_col(df):\n",
        "    \"\"\"Return the label/activity column name.\"\"\"\n",
        "    for c in df.columns:\n",
        "        cu = c.strip().upper()\n",
        "        if cu in (\"ACTIVITY\", \"LABEL\", \"CLASS\", \"TARGET\", \"Y\"):\n",
        "            return c\n",
        "    raise ValueError(f\"No label column found. Columns: {list(df.columns[:10])}\")\n",
        "\n",
        "\n",
        "# â”€â”€ Load SMILES files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def load_smiles_file(path):\n",
        "    \"\"\"\n",
        "    Load a SMILES CSV. Normalises column names to SMILES + Label.\n",
        "    Returns DataFrame with at minimum ['SMILES', 'Label'] columns.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    smiles_col = find_smiles_col(df)\n",
        "    label_col  = find_label_col(df)\n",
        "\n",
        "    df = df.rename(columns={smiles_col: \"SMILES\", label_col: \"Label\"})\n",
        "    df[\"Label\"] = pd.to_numeric(df[\"Label\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "    return df[[\"SMILES\", \"Label\"]].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# â”€â”€ Load fingerprint / descriptor files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def load_fp_file(fp_path, smiles_df):\n",
        "    \"\"\"\n",
        "    Load a descriptor CSV.\n",
        "    Labels are aligned by row index from the companion SMILES DataFrame.\n",
        "\n",
        "    Handles two cases:\n",
        "      (a) FP file has its own SMILES column â†’ inner-merge on SMILES\n",
        "      (b) FP file has no SMILES column     â†’ row-wise concatenation\n",
        "\n",
        "    In either case the returned DataFrame has:\n",
        "      - All descriptor feature columns\n",
        "      - 'SMILES'  column\n",
        "      - 'Label'   column\n",
        "    \"\"\"\n",
        "    fp_df = pd.read_csv(fp_path)\n",
        "    fp_df.columns = fp_df.columns.str.strip()\n",
        "\n",
        "    # Try to find a SMILES column in the FP file\n",
        "    try:\n",
        "        smiles_col_fp = find_smiles_col(fp_df)\n",
        "        fp_df = fp_df.rename(columns={smiles_col_fp: \"SMILES\"})\n",
        "        # Merge on SMILES string\n",
        "        merged = fp_df.merge(smiles_df[[\"SMILES\", \"Label\"]], on=\"SMILES\", how=\"inner\")\n",
        "        print(f\"  [load_fp] Merged on SMILES: {len(merged)} rows  ({fp_path.split('/')[-1]})\")\n",
        "    except ValueError:\n",
        "        # No SMILES column in FP file â€” align by row index\n",
        "        n = min(len(fp_df), len(smiles_df))\n",
        "        merged = fp_df.iloc[:n].copy().reset_index(drop=True)\n",
        "        merged[\"SMILES\"] = smiles_df[\"SMILES\"].iloc[:n].values\n",
        "        merged[\"Label\"]  = smiles_df[\"Label\"].iloc[:n].values\n",
        "        print(f\"  [load_fp] Row-aligned: {n} rows  ({fp_path.split('/')[-1]})\")\n",
        "\n",
        "    # Drop any rows where Label is NaN\n",
        "    merged = merged.dropna(subset=[\"Label\"]).reset_index(drop=True)\n",
        "    merged[\"Label\"] = merged[\"Label\"].astype(int)\n",
        "    return merged\n",
        "\n",
        "\n",
        "# â”€â”€ Execute data loading â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"Loading SMILES files...\")\n",
        "df_train_s = load_smiles_file(SMILES_TRAIN)\n",
        "df_t1_s    = load_smiles_file(SMILES_TEST1)\n",
        "df_t2_s    = load_smiles_file(SMILES_TEST2)\n",
        "df_t3_s    = load_smiles_file(SMILES_TEST3)\n",
        "\n",
        "print(\"\\nLoading fingerprint/descriptor files...\")\n",
        "df_train_fp = load_fp_file(FP_TRAIN, df_train_s)\n",
        "df_t1_fp    = load_fp_file(FP_TEST1,  df_t1_s)\n",
        "df_t2_fp    = load_fp_file(FP_TEST2,  df_t2_s)\n",
        "df_t3_fp    = load_fp_file(FP_TEST3,  df_t3_s)\n",
        "\n",
        "# â”€â”€ Extract label arrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "y_train = df_train_fp[\"Label\"].values.astype(np.float32)\n",
        "y_t1    = df_t1_fp[\"Label\"].values.astype(np.float32)\n",
        "y_t2    = df_t2_fp[\"Label\"].values.astype(np.float32)\n",
        "y_t3    = df_t3_fp[\"Label\"].values.astype(np.float32)\n",
        "\n",
        "print(f\"\\n{'Dataset':<12} {'N':>6} {'Toxic %':>8}\")\n",
        "print(\"-\" * 28)\n",
        "for nm, y in [(\"Train\", y_train), (\"Test1\", y_t1), (\"Test2\", y_t2), (\"Test3\", y_t3)]:\n",
        "    print(f\"{nm:<12} {len(y):>6} {y.mean():>7.1%}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:26:29.135453Z",
          "iopub.execute_input": "2026-02-25T05:26:29.135755Z",
          "iopub.status.idle": "2026-02-25T05:26:40.290194Z",
          "shell.execute_reply.started": "2026-02-25T05:26:29.135736Z",
          "shell.execute_reply": "2026-02-25T05:26:40.289583Z"
        },
        "id": "6c4d7c25-2b13-48c8-a27a-e723efb68cbb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Â· Class Distribution"
      ],
      "metadata": {
        "id": "1b3c8d8c-90cd-4e84-8685-85b0b05d53c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_class_distribution(labels_dict, save_path):\n",
        "    sets      = list(labels_dict.keys())\n",
        "    pos_counts = [int(labels_dict[k].sum()) for k in sets]\n",
        "    neg_counts = [len(labels_dict[k]) - int(labels_dict[k].sum()) for k in sets]\n",
        "\n",
        "    x, width = np.arange(len(sets)), 0.35\n",
        "    fig, ax = plt.subplots(figsize=(7, 4))\n",
        "    ax.bar(x - width/2, neg_counts, width, label=\"Non-toxic (0)\", color=\"#4C72B0\")\n",
        "    ax.bar(x + width/2, pos_counts, width, label=\"Toxic (1)\",     color=\"#C44E52\")\n",
        "    ax.set_xticks(x); ax.set_xticklabels(sets)\n",
        "    ax.set_ylabel(\"Compound Count\")\n",
        "    ax.set_title(\"Class Distribution Across Datasets\")\n",
        "    ax.legend(); plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150); plt.show(); plt.close()\n",
        "\n",
        "plot_class_distribution(\n",
        "    {\"Train\": y_train, \"Test1\": y_t1, \"Test2\": y_t2, \"Test3\": y_t3},\n",
        "    f\"{OUTPUT_DIR}/class_distribution.png\"\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:26:40.291009Z",
          "iopub.execute_input": "2026-02-25T05:26:40.291256Z",
          "iopub.status.idle": "2026-02-25T05:26:40.610033Z",
          "shell.execute_reply.started": "2026-02-25T05:26:40.291235Z",
          "shell.execute_reply": "2026-02-25T05:26:40.60943Z"
        },
        "id": "1cca4ff3-53bd-46f0-9682-f6b472e2e8c9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Â· SMILES Tokenisation\n",
        "\n",
        "SMILES strings are treated as **character-level sequences**. Each unique character in the training set becomes a vocabulary token. Sequences are padded (or truncated) to `MAX_LEN = 120` characters.\n",
        "\n",
        "> Example: `CC(=O)Oc1ccccc1C(=O)O` â†’ `[3, 3, 11, 2, 15, 5, ...]` (integer indices)\n"
      ],
      "metadata": {
        "id": "bbea6904-282a-4ec4-897c-a959a81e61de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SMILESTokenizer:\n",
        "    \"\"\"Character-level tokeniser for SMILES strings.\"\"\"\n",
        "    PAD = 0\n",
        "\n",
        "    def __init__(self):\n",
        "        self.char2idx  = {}\n",
        "        self.vocab_size = 0\n",
        "\n",
        "    def fit(self, smiles_list):\n",
        "        chars = set()\n",
        "        for s in smiles_list:\n",
        "            chars.update(list(str(s)))\n",
        "        self.char2idx  = {c: i + 1 for i, c in enumerate(sorted(chars))}\n",
        "        self.vocab_size = len(self.char2idx)\n",
        "        return self\n",
        "\n",
        "    def encode(self, smiles_list, max_len=120):\n",
        "        seqs = []\n",
        "        for s in smiles_list:\n",
        "            ids = [self.char2idx.get(c, 0) for c in str(s)[:max_len]]\n",
        "            ids = ids + [0] * max(0, max_len - len(ids))   # pad\n",
        "            seqs.append(ids)\n",
        "        return np.array(seqs, dtype=np.int64)\n",
        "\n",
        "# â”€â”€ Fit on training SMILES only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "tokenizer = SMILESTokenizer()\n",
        "tokenizer.fit(df_train_fp[\"SMILES\"].tolist())\n",
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "print(f\"Vocabulary size : {VOCAB_SIZE} unique characters\")\n",
        "\n",
        "# â”€â”€ Encode all sets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "X_seq_train = tokenizer.encode(df_train_fp[\"SMILES\"].tolist(), MAX_LEN)\n",
        "X_seq_t1    = tokenizer.encode(df_t1_fp[\"SMILES\"].tolist(),    MAX_LEN)\n",
        "X_seq_t2    = tokenizer.encode(df_t2_fp[\"SMILES\"].tolist(),    MAX_LEN)\n",
        "X_seq_t3    = tokenizer.encode(df_t3_fp[\"SMILES\"].tolist(),    MAX_LEN)\n",
        "\n",
        "print(f\"X_seq_train shape : {X_seq_train.shape}\")\n",
        "print(f\"X_seq_test1 shape : {X_seq_t1.shape}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:26:40.610941Z",
          "iopub.execute_input": "2026-02-25T05:26:40.611215Z",
          "iopub.status.idle": "2026-02-25T05:26:40.756654Z",
          "shell.execute_reply.started": "2026-02-25T05:26:40.611193Z",
          "shell.execute_reply": "2026-02-25T05:26:40.755981Z"
        },
        "id": "4828be6d-98c9-4c1f-a14e-f001197cc747"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 Â· Fingerprint Descriptor Selection via LASSO\n",
        "\n",
        "### How LASSO Is Applied\n",
        "\n",
        "**Input:** Raw descriptor matrix `X_fp_train_raw` â€” shape `(N_train, ~1800)` â€” containing Mordred, PubChem, and MACCS fingerprint features.\n",
        "\n",
        "**Step-by-step process:**\n",
        "\n",
        "1. **StandardScaler** normalises each feature to zero mean and unit variance (required because LASSO penalises coefficients and unscaled features bias it toward low-variance columns).\n",
        "2. **LassoCV** fits a linear model with L1 regularisation (Î± selected via 5-fold CV across 50 log-spaced values in `[1e-4, 1e-1]`). The L1 penalty drives irrelevant feature coefficients **exactly to zero**.\n",
        "3. A **binary mask** `lasso_mask` is extracted: `True` for any feature with a non-zero coefficient.\n",
        "4. The same `StandardScaler` (fit only on training data) transforms test sets, then `lasso_mask` filters them â€” **no data leakage**.\n",
        "5. A **fallback** keeps at least 10 features if LASSO zeros everything (rare with high Î±).\n",
        "\n",
        "```\n",
        "X_fp_train_raw  (N, ~1800)\n",
        "       â†“  StandardScaler.fit_transform\n",
        "X_fp_train_sc   (N, ~1800)\n",
        "       â†“  LassoCV(cv=5).fit â†’ lasso_mask (bool array)\n",
        "X_fp_train      (N, FP_DIM)   â† deep learning model input\n",
        "```\n",
        "\n",
        "> **Why regression LASSO on binary labels?** This is valid as a *feature selector* â€” L1 regression identifies the linearly-most-discriminative descriptors, which are then passed to the non-linear deep model. Coefficients reflect linear predictive strength; a zero coefficient means the feature adds no marginal linear signal."
      ],
      "metadata": {
        "id": "7ca2d883-2e87-4d37-8b41-51c71cc61c7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Step 1: identify purely numeric descriptor columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Some CSVs mix in string metadata columns (e.g. notes like\n",
        "# 'multiple fragments (SpAbs_A/SpAbs)'). We keep only columns\n",
        "# that are numeric across ALL four datasets.\n",
        "\n",
        "non_feat_cols = {\"SMILES\", \"Label\"}\n",
        "\n",
        "def get_numeric_fp_cols(df_train_fp, df_t1_fp, df_t2_fp, df_t3_fp):\n",
        "    \"\"\"\n",
        "    Return descriptor column names that are:\n",
        "      1. Present in all four DataFrames\n",
        "      2. Fully numeric in the training set (no string values)\n",
        "      3. Non-zero variance in the training set\n",
        "    \"\"\"\n",
        "    candidates = [c for c in df_train_fp.columns if c not in non_feat_cols]\n",
        "\n",
        "    # Keep only columns present in every test set too\n",
        "    for df in [df_t1_fp, df_t2_fp, df_t3_fp]:\n",
        "        test_cols = set(df.columns)\n",
        "        candidates = [c for c in candidates if c in test_cols]\n",
        "\n",
        "    # Coerce to numeric; drop columns with any non-numeric values\n",
        "    train_sub = df_train_fp[candidates].apply(pd.to_numeric, errors=\"coerce\")\n",
        "    all_numeric = train_sub.columns[train_sub.notna().all()].tolist()\n",
        "\n",
        "    # Drop zero-variance (constant) columns\n",
        "    non_const = [c for c in all_numeric if train_sub[c].std() > 0]\n",
        "\n",
        "    dropped_str = len(candidates)  - len(all_numeric)\n",
        "    dropped_var = len(all_numeric) - len(non_const)\n",
        "    print(f\"[FP cols] Candidates        : {len(candidates)}\")\n",
        "    print(f\"[FP cols] Dropped (non-numeric): {dropped_str}\")\n",
        "    print(f\"[FP cols] Dropped (zero-var)   : {dropped_var}\")\n",
        "    print(f\"[FP cols] Remaining            : {len(non_const)}\")\n",
        "    return non_const\n",
        "\n",
        "fp_cols = get_numeric_fp_cols(df_train_fp, df_t1_fp, df_t2_fp, df_t3_fp)\n",
        "\n",
        "# â”€â”€ Step 2: build raw float matrices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def safe_fp_matrix(df, cols):\n",
        "    \"\"\"Coerce to numeric, fill NaN with 0, return float32 array.\"\"\"\n",
        "    return (df[cols]\n",
        "            .apply(pd.to_numeric, errors=\"coerce\")\n",
        "            .fillna(0)\n",
        "            .values.astype(np.float32))\n",
        "\n",
        "X_fp_train_raw = safe_fp_matrix(df_train_fp, fp_cols)\n",
        "X_fp_t1_raw   = safe_fp_matrix(df_t1_fp,    fp_cols)\n",
        "X_fp_t2_raw   = safe_fp_matrix(df_t2_fp,    fp_cols)\n",
        "X_fp_t3_raw   = safe_fp_matrix(df_t3_fp,    fp_cols)\n",
        "print(f\"Raw descriptor matrix shape (train): {X_fp_train_raw.shape}\")\n",
        "\n",
        "# â”€â”€ Step 3: LASSO feature selection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def lasso_select(X_train, y_train, X_tests, alphas=None):\n",
        "    \"\"\"\n",
        "    Fit LassoCV on standardised training descriptors.\n",
        "    Returns selected subsets for train + all test sets.\n",
        "    Includes inf/nan cleanup after scaling.\n",
        "    \"\"\"\n",
        "    if alphas is None:\n",
        "        alphas = np.logspace(-4, -1, 50)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_tr_sc = scaler.fit_transform(X_train)\n",
        "    X_tr_sc = np.nan_to_num(X_tr_sc, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    print(\"[LASSO] Fitting LassoCV (this may take 1-2 min)...\")\n",
        "    lasso = LassoCV(cv=5, alphas=alphas, max_iter=10000, random_state=SEED, n_jobs=-1)\n",
        "    lasso.fit(X_tr_sc, y_train)\n",
        "\n",
        "    mask = lasso.coef_ != 0\n",
        "    print(f\"[LASSO] Selected {mask.sum()} / {X_train.shape[1]} features  \"\n",
        "          f\"(alpha = {lasso.alpha_:.5f})\")\n",
        "\n",
        "    # Fallback: if LASSO zeros everything out, use top-10 by |coef|\n",
        "    if mask.sum() == 0:\n",
        "        print(\"[LASSO] Warning: 0 features selected â€” falling back to top-10 by |coef|\")\n",
        "        top10 = np.argsort(np.abs(lasso.coef_))[-10:]\n",
        "        mask[top10] = True\n",
        "\n",
        "    X_tr_sel    = X_tr_sc[:, mask]\n",
        "    X_tests_sel = []\n",
        "    for Xt in X_tests:\n",
        "        Xt_sc = np.nan_to_num(scaler.transform(Xt), nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        X_tests_sel.append(Xt_sc[:, mask])\n",
        "\n",
        "    return X_tr_sel, X_tests_sel, mask, scaler\n",
        "\n",
        "X_fp_train, (X_fp_t1, X_fp_t2, X_fp_t3), lasso_mask, fp_scaler = lasso_select(\n",
        "    X_fp_train_raw, y_train,\n",
        "    [X_fp_t1_raw, X_fp_t2_raw, X_fp_t3_raw]\n",
        ")\n",
        "\n",
        "FP_DIM = X_fp_train.shape[1]\n",
        "sel_feature_names = [fp_cols[i] for i in range(len(fp_cols)) if lasso_mask[i]]\n",
        "print(f\"FP_DIM (model input) : {FP_DIM}\")\n",
        "print(f\"Example selected features: {sel_feature_names[:5]}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:26:40.757624Z",
          "iopub.execute_input": "2026-02-25T05:26:40.757861Z",
          "iopub.status.idle": "2026-02-25T05:31:13.748739Z",
          "shell.execute_reply.started": "2026-02-25T05:26:40.757842Z",
          "shell.execute_reply": "2026-02-25T05:31:13.747954Z"
        },
        "id": "d2dfe783-b431-41ba-8fb2-a51b1a3ea9d4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 Â· Model Architecture\n",
        "\n",
        "### 6.1 SMILES Branch â€” 1D-CNN Sequence Encoder\n",
        "Learns local chemical motif patterns from character sequences through two convolutional layers followed by global max-pooling.\n",
        "\n",
        "### 6.2 Fingerprint Branch â€” MLP Descriptor Encoder  \n",
        "Two fully-connected layers with BatchNorm and Dropout map the selected descriptors to a 128-dimensional embedding.\n",
        "\n",
        "### 6.3 Cross-Attention Fusion\n",
        "Both branch outputs are treated as query/key/value pairs in a multi-head attention block:\n",
        "- SMILES features **attend** to fingerprint features â†’ `f_s'`\n",
        "- Fingerprint features **attend** to SMILES features â†’ `f_f'`\n",
        "\n",
        "### 6.4 Softmax Gating\n",
        "A small linear network maps the concatenated attended vectors to scalar gates `(g_s, g_f)` via softmax, ensuring `g_s + g_f = 1`. The final fused vector is:\n",
        "\n",
        "$$F = g_s \\cdot f_s' + g_f \\cdot f_f'$$\n",
        "\n",
        "The gate values reveal which modality the model relies on for each prediction.\n"
      ],
      "metadata": {
        "id": "58ffd82c-8581-4633-93dc-e3fab72d6c9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 Â· Four Fusion Mechanisms\n",
        "\n",
        "We implement and compare **four distinct fusion strategies** that combine the SMILES branch embedding `f_s` and the fingerprint branch embedding `f_f`:\n",
        "\n",
        "| Fusion | Description |\n",
        "|---|---|\n",
        "| **Concatenation** | Direct concat `[f_s; f_f]` â†’ Linear(256,128) â€” no cross-modal interaction |\n",
        "| **Attention-only** | Cross-attention between branches, sum of attended outputs |\n",
        "| **Gate-only** | Softmax gating `g_sÂ·f_s + g_fÂ·f_f` â€” weighted combination without attention |\n",
        "| **Gated-Attention** | Cross-attention + softmax gating (full model) â€” attended features are gated |\n",
        "\n",
        "The comparison table in Section 15 reports all four on the external test sets."
      ],
      "metadata": {
        "id": "89urKfOPhi7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# Â§6 â€” Four Fusion Variants  (FIXED: multi-token attention)\n",
        "# =================================================================\n",
        "\n",
        "# Shared constants\n",
        "N_TOKENS  = 8    # each 128-d vector split into 8 tokens of 16-d\n",
        "TOKEN_DIM = 16   # 128 / N_TOKENS -- must divide evenly\n",
        "# WHY: unsqueeze(1) -> (B,1,128): 1 key -> softmax(scalar)=1.0 ALWAYS.\n",
        "# Reshape to  (B,8,16): 8 keys -> softmax learns a real distribution.\n",
        "\n",
        "\n",
        "class SequenceBranch(nn.Module):\n",
        "    \"\"\"SMILES Encoder: Embedding -> Conv1D x2 -> AdaptiveMaxPool -> FC(128) + LayerNorm\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=64, conv_channels=128, kernel_size=5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n",
        "        self.conv1   = nn.Conv1d(embed_dim, conv_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.conv2   = nn.Conv1d(conv_channels, conv_channels, kernel_size=3, padding=1)\n",
        "        self.pool    = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc      = nn.Linear(conv_channels, 128)\n",
        "        self.norm    = nn.LayerNorm(128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.embedding(x).permute(0, 2, 1)\n",
        "        e = F.relu(self.conv1(e))\n",
        "        e = F.relu(self.conv2(e))\n",
        "        e = self.pool(e).squeeze(2)\n",
        "        e = self.dropout(e)\n",
        "        return self.norm(F.relu(self.fc(e)))\n",
        "\n",
        "\n",
        "class FingerprintBranch(nn.Module):\n",
        "    \"\"\"Descriptor Encoder: FC(512)->FC(256)->FC(128) + residual skip + LayerNorm\"\"\"\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.fc1     = nn.Linear(in_dim, 512)\n",
        "        self.bn1     = nn.BatchNorm1d(512)\n",
        "        self.fc2     = nn.Linear(512, 256)\n",
        "        self.bn2     = nn.BatchNorm1d(256)\n",
        "        self.fc3     = nn.Linear(256, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.norm    = nn.LayerNorm(128)\n",
        "        self.skip    = nn.Linear(in_dim, 128, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.skip(x)\n",
        "        x = self.bn1(F.relu(self.fc1(x))); x = self.dropout(x)\n",
        "        x = self.bn2(F.relu(self.fc2(x))); x = self.dropout(x)\n",
        "        return self.norm(F.relu(self.fc3(x) + residual))\n",
        "\n",
        "\n",
        "def to_tokens(x, n_tokens=N_TOKENS, token_dim=TOKEN_DIM):\n",
        "    \"\"\"\n",
        "    Reshape (B, 128) -> (B, n_tokens, token_dim).\n",
        "    Gives attention softmax n_tokens keys to distribute over (instead of 1).\n",
        "    Zero parameters -- pure reshape.\n",
        "    \"\"\"\n",
        "    return x.view(x.size(0), n_tokens, token_dim)   # (B, 8, 16)\n",
        "\n",
        "\n",
        "def from_tokens(x_tok):\n",
        "    \"\"\"\n",
        "    Collapse (B, n_tokens, token_dim) -> (B, n_tokens*token_dim) = (B, 128).\n",
        "    Uses flatten instead of mean-pool:\n",
        "      mean(dim=1) on (B,8,16) -> (B,16)  [WRONG - loses 7/8 of the representation]\n",
        "      flatten(1)  on (B,8,16) -> (B,128) [CORRECT - preserves all token info]\n",
        "    \"\"\"\n",
        "    return x_tok.flatten(start_dim=1)   # (B, 8*16) = (B, 128)\n",
        "\n",
        "\n",
        "# -- Fusion 1: Direct Concatenation --\n",
        "class ConcatFusionNet(nn.Module):\n",
        "    \"\"\"Concat [f_s ; f_f] -> Linear(256,128) -- no cross-modal interaction.\"\"\"\n",
        "    def __init__(self, vocab_size, fp_dim, embed_dim=64, conv_ch=128, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.seq_branch = SequenceBranch(vocab_size, embed_dim, conv_ch)\n",
        "        self.fp_branch  = FingerprintBranch(fp_dim)\n",
        "        self.fusion     = nn.Sequential(\n",
        "            nn.Linear(256, 128), nn.ReLU(), nn.LayerNorm(128), nn.Dropout(0.3)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),  nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(32, 1),   nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, seq, fp):\n",
        "        f_s = self.seq_branch(seq)\n",
        "        f_f = self.fp_branch(fp)\n",
        "        fused = self.fusion(torch.cat([f_s, f_f], dim=1))\n",
        "        out = self.classifier(fused).squeeze(1)\n",
        "        g_s = torch.full((seq.size(0),), 0.5, device=seq.device)\n",
        "        g_f = torch.full((fp.size(0),),  0.5, device=fp.device)\n",
        "        return out, (g_s, g_f)\n",
        "\n",
        "\n",
        "# -- Fusion 2: Attention-Only --\n",
        "class AttentionFusionNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-token cross-attention fusion.\n",
        "    TOKEN_DIM=16 with n_heads=4 -> head_dim=4 (valid).\n",
        "    Separate attn_s2f / attn_f2s modules break direction symmetry.\n",
        "    Gate conditioned on RAW features, not attended features.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, fp_dim, embed_dim=64, conv_ch=128, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.seq_branch  = SequenceBranch(vocab_size, embed_dim, conv_ch)\n",
        "        self.fp_branch   = FingerprintBranch(fp_dim)\n",
        "        self.attn_s2f    = nn.MultiheadAttention(TOKEN_DIM, n_heads, batch_first=True, dropout=0.1)\n",
        "        self.attn_f2s    = nn.MultiheadAttention(TOKEN_DIM, n_heads, batch_first=True, dropout=0.1)\n",
        "        self.branch_gate = nn.Linear(256, 2)\n",
        "        self.classifier  = nn.Sequential(\n",
        "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),  nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(32, 1),   nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, seq, fp):\n",
        "        f_s = self.seq_branch(seq)   # (B, 128)\n",
        "        f_f = self.fp_branch(fp)     # (B, 128)\n",
        "\n",
        "        s_tok = to_tokens(f_s)       # (B, 8, 16)\n",
        "        f_tok = to_tokens(f_f)       # (B, 8, 16)\n",
        "\n",
        "        s_att_tok, _ = self.attn_s2f(s_tok, f_tok, f_tok)\n",
        "        f_att_tok, _ = self.attn_f2s(f_tok, s_tok, s_tok)\n",
        "\n",
        "        f_s_att = from_tokens(s_att_tok)   # (B, 128)\n",
        "        f_f_att = from_tokens(f_att_tok)   # (B, 128)\n",
        "\n",
        "        gate = torch.softmax(self.branch_gate(torch.cat([f_s, f_f], dim=1)), dim=1)\n",
        "        g_s, g_f = gate[:, 0:1], gate[:, 1:2]\n",
        "\n",
        "        fused = g_s * f_s_att + g_f * f_f_att\n",
        "        out = self.classifier(fused).squeeze(1)\n",
        "        return out, (g_s.squeeze(1), g_f.squeeze(1))\n",
        "\n",
        "\n",
        "# -- Fusion 3: Gate-Only (no attention) --\n",
        "class GateFusionNet(nn.Module):\n",
        "    \"\"\"Softmax gating: g_s*f_s + g_f*f_f -- weighted blend without cross-attention.\"\"\"\n",
        "    def __init__(self, vocab_size, fp_dim, embed_dim=64, conv_ch=128, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.seq_branch = SequenceBranch(vocab_size, embed_dim, conv_ch)\n",
        "        self.fp_branch  = FingerprintBranch(fp_dim)\n",
        "        self.gate_fc    = nn.Linear(256, 2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),  nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(32, 1),   nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, seq, fp):\n",
        "        f_s = self.seq_branch(seq)\n",
        "        f_f = self.fp_branch(fp)\n",
        "        g = torch.softmax(self.gate_fc(torch.cat([f_s, f_f], dim=1)), dim=1)\n",
        "        g_s, g_f = g[:, 0:1], g[:, 1:2]\n",
        "        fused = g_s * f_s + g_f * f_f\n",
        "        out = self.classifier(fused).squeeze(1)\n",
        "        return out, (g_s.squeeze(1), g_f.squeeze(1))\n",
        "\n",
        "\n",
        "# -- Fusion 4: Gated-Attention (full model) --\n",
        "class MultiModalCardioNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Gated cross-attention fusion with multi-token decomposition.\n",
        "\n",
        "    FIXES vs old version:\n",
        "      1. to_tokens(): (B,128)->(B,8,16) so softmax has 8 keys -> non-uniform weights.\n",
        "         Old unsqueeze(1): (B,1,128) -> softmax of 1 scalar = 1.0 always.\n",
        "      2. Separate attn_s2f / attn_f2s: independent weights break direction symmetry.\n",
        "      3. Richer gate input: raw features + attention residuals (512-d total).\n",
        "      4. Raw residual skip connection (gradient highway).\n",
        "      5. Deeper classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, fp_dim, embed_dim=64, conv_ch=128, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.seq_branch  = SequenceBranch(vocab_size, embed_dim, conv_ch)\n",
        "        self.fp_branch   = FingerprintBranch(fp_dim)\n",
        "        # TOKEN_DIM=16, n_heads=4 -> head_dim=4 (valid)\n",
        "        self.attn_s2f    = nn.MultiheadAttention(TOKEN_DIM, n_heads, batch_first=True, dropout=0.1)\n",
        "        self.attn_f2s    = nn.MultiheadAttention(TOKEN_DIM, n_heads, batch_first=True, dropout=0.1)\n",
        "        # Gate: raw (256) + residuals (256) = 512 -> 128 -> 2\n",
        "        self.gate_fc     = nn.Sequential(\n",
        "            nn.Linear(512, 128), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "        self.raw_proj    = nn.Sequential(nn.Linear(256, 128), nn.ReLU(), nn.LayerNorm(128))\n",
        "        self.blend_norm  = nn.LayerNorm(128)\n",
        "        self.classifier  = nn.Sequential(\n",
        "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),  nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(32, 16),  nn.ReLU(), nn.Dropout(0.1),\n",
        "            nn.Linear(16, 1),   nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, seq, fp):\n",
        "        f_s = self.seq_branch(seq)   # (B, 128)\n",
        "        f_f = self.fp_branch(fp)     # (B, 128)\n",
        "\n",
        "        s_tok = to_tokens(f_s)       # (B, 8, 16)\n",
        "        f_tok = to_tokens(f_f)       # (B, 8, 16)\n",
        "\n",
        "        s_att_tok, _ = self.attn_s2f(s_tok, f_tok, f_tok)\n",
        "        f_att_tok, _ = self.attn_f2s(f_tok, s_tok, s_tok)\n",
        "\n",
        "        f_s_att = from_tokens(s_att_tok)   # (B, 128)\n",
        "        f_f_att = from_tokens(f_att_tok)   # (B, 128)\n",
        "\n",
        "        delta_s = f_s_att - f_s\n",
        "        delta_f = f_f_att - f_f\n",
        "\n",
        "        gate_input  = torch.cat([f_s, f_f, delta_s, delta_f], dim=1)   # (B, 512)\n",
        "        gate        = torch.softmax(self.gate_fc(gate_input), dim=1)    # (B, 2)\n",
        "        g_s, g_f    = gate[:, 0:1], gate[:, 1:2]\n",
        "\n",
        "        gated_blend = g_s * f_s_att + g_f * f_f_att\n",
        "        raw_res     = self.raw_proj(torch.cat([f_s, f_f], dim=1))\n",
        "        fused       = self.blend_norm(gated_blend + raw_res)\n",
        "\n",
        "        out = self.classifier(fused).squeeze(1)\n",
        "        return out, (g_s.squeeze(1), g_f.squeeze(1))\n",
        "\n",
        "\n",
        "# -- Sanity checks --\n",
        "_s_dummy = torch.zeros(4, MAX_LEN, dtype=torch.long).to(DEVICE)\n",
        "_f_dummy = torch.zeros(4, FP_DIM,  dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "for _cls, _name in [\n",
        "    (ConcatFusionNet,     'ConcatFusionNet'),\n",
        "    (AttentionFusionNet,  'AttentionFusionNet'),\n",
        "    (GateFusionNet,       'GateFusionNet'),\n",
        "    (MultiModalCardioNet, 'MultiModalCardioNet'),\n",
        "]:\n",
        "    _m = _cls(VOCAB_SIZE, FP_DIM, n_heads=N_HEADS).to(DEVICE)\n",
        "    _out, (_gs, _gf) = _m(_s_dummy, _f_dummy)\n",
        "    assert _out.shape == (4,), f'{_name}: expected (4,), got {_out.shape}'\n",
        "    _n = sum(p.numel() for p in _m.parameters() if p.requires_grad)\n",
        "    print(f'  [OK] {_name:<26} output={_out.shape}  '\n",
        "          f'gate_s={_gs.mean():.3f}  gate_f={_gf.mean():.3f}  params={_n:,}')\n",
        "\n",
        "print('\\n[SANITY] All 4 fusion models pass shape checks.')\n",
        "print('Models: ConcatFusionNet | AttentionFusionNet | GateFusionNet | MultiModalCardioNet')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "8e049fc1-180d-419e-90fb-bca3d42b7696",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:31:13.750822Z",
          "iopub.execute_input": "2026-02-25T05:31:13.751088Z",
          "iopub.status.idle": "2026-02-25T05:31:15.001154Z",
          "shell.execute_reply.started": "2026-02-25T05:31:13.751066Z",
          "shell.execute_reply": "2026-02-25T05:31:15.000365Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 Â· Dataset & DataLoader"
      ],
      "metadata": {
        "id": "db267396-2591-4ee2-9668-d26a47cd4262"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CardioDataset(Dataset):\n",
        "    def __init__(self, seq, fp, labels):\n",
        "        self.seq = torch.tensor(seq,    dtype=torch.long)\n",
        "        self.fp  = torch.tensor(fp,     dtype=torch.float32)\n",
        "        self.y   = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.seq[idx], self.fp[idx], self.y[idx]\n",
        "\n",
        "print(\"CardioDataset class ready.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "956e9c67-b857-4710-8e94-0f616537c384",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:31:15.002425Z",
          "iopub.execute_input": "2026-02-25T05:31:15.002684Z",
          "iopub.status.idle": "2026-02-25T05:31:15.007875Z",
          "shell.execute_reply.started": "2026-02-25T05:31:15.002664Z",
          "shell.execute_reply": "2026-02-25T05:31:15.00716Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8 Â· Improved Training Utilities\n",
        "\n",
        "Key changes from v1:\n",
        "- **Weighted BCELoss** â€” positive class gets weight `neg_count / pos_count` to correct for imbalance\n",
        "- **Gate entropy regularisation** â€” adds a small penalty when gate entropy is low (i.e. one modality dominates), encouraging balanced fusion\n",
        "- **Early stopping on AUC** instead of loss â€” AUC is more informative than loss for imbalanced data\n"
      ],
      "metadata": {
        "id": "3ec66d6a-31d9-4126-939a-7b22d4153cf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, y_prob, threshold=0.5):\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    return {\n",
        "        \"ROC-AUC\" : roc_auc_score(y_true, y_prob),\n",
        "        \"F1\"      : f1_score(y_true, y_pred,       zero_division=0),\n",
        "        \"ACC\"     : accuracy_score(y_true, y_pred),\n",
        "        \"MCC\"     : matthews_corrcoef(y_true, y_pred),\n",
        "        \"AUPR\"    : average_precision_score(y_true, y_prob),\n",
        "    }\n",
        "\n",
        "\n",
        "def find_optimal_threshold(y_true, y_prob):\n",
        "    \"\"\"Youden's J statistic: threshold maximising (TPR - FPR).\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
        "    j_scores = tpr - fpr\n",
        "    return float(thresholds[np.argmax(j_scores)])\n",
        "\n",
        "\n",
        "def compute_pos_weight(y_train):\n",
        "    \"\"\"pos_weight = neg_count / pos_count for BCEWithLogitsLoss-style weighting.\"\"\"\n",
        "    neg = (y_train == 0).sum()\n",
        "    pos = (y_train == 1).sum()\n",
        "    return float(neg / pos)\n",
        "\n",
        "\n",
        "# NOTE: MixUp augmentation removed â€” showed no measurable improvement.\n",
        "\n",
        "\n",
        "def gate_entropy_loss(g_s, g_f, min_weight=0.1, penalty=0.5):\n",
        "    \"\"\"\n",
        "    Regularisation: penalise when either gate weight < min_weight.\n",
        "    Forces the model to use both modalities (prevents gate collapse).\n",
        "\n",
        "    NOTE: ConcatFusionNet returns constant tensors (created with torch.full,\n",
        "    no grad), so this loss correctly produces 0 for it â€” no wasted computation.\n",
        "    For AttentionFusionNet and MultiModalCardioNet both g_s and g_f are\n",
        "    output by learned softmax layers and CAN be penalised.\n",
        "    \"\"\"\n",
        "    loss_s = F.relu(min_weight - g_s).mean()\n",
        "    loss_f = F.relu(min_weight - g_f).mean()\n",
        "    return penalty * (loss_s + loss_f)\n",
        "\n",
        "\n",
        "def focal_bce_loss(pred, target, pos_weight_tensor, device,\n",
        "                   gamma=2.0, label_smoothing=0.05):\n",
        "    \"\"\"\n",
        "    Focal-weighted, label-smoothed BCE â€” for MultiModalCardioNet training.\n",
        "\n",
        "    Improvements over plain weighted BCE (no model components changed):\n",
        "      â€¢ Label smoothing (Îµ=0.05): softens hard 0/1 targets to [Îµ/2, 1âˆ’Îµ/2],\n",
        "        preventing overconfident predictions and improving calibration.\n",
        "      â€¢ Focal weighting (Î³=2): down-weights easy examples so the model focuses\n",
        "        more on hard-to-classify samples, boosting minority-class recall.\n",
        "\n",
        "    Both are purely training-time loss modifications â€” model architecture\n",
        "    is identical to the original MultiModalCardioNet.\n",
        "    \"\"\"\n",
        "    # Label smoothing\n",
        "    eps = label_smoothing\n",
        "    smooth_target = target * (1.0 - eps) + eps / 2.0\n",
        "\n",
        "    # Per-sample class weight (same neg/pos ratio as original)\n",
        "    pw = pos_weight_tensor.to(device)\n",
        "    weights = torch.where(target >= 0.5, pw, torch.ones(1, device=device))\n",
        "\n",
        "    # BCE per sample (no reduction)\n",
        "    bce = F.binary_cross_entropy(pred, smooth_target, weight=weights, reduction=\"none\")\n",
        "\n",
        "    # Focal modulation: p_t is model confidence for the true class\n",
        "    p_t = pred * target + (1.0 - pred) * (1.0 - target)\n",
        "    focal_weight = (1.0 - p_t) ** gamma\n",
        "\n",
        "    return (focal_weight * bce).mean()\n",
        "\n",
        "\n",
        "def run_epoch(model, loader, optimizer, criterion, device, train=True,\n",
        "              pos_weight_tensor=None, gate_penalty=0.3, use_focal=False):\n",
        "    \"\"\"\n",
        "    Training/evaluation epoch.\n",
        "    Returns: avg_loss, auc_val, aupr_val, acc_val\n",
        "\n",
        "    Args:\n",
        "        gate_penalty  : coefficient for gate entropy regularisation (default 0.3).\n",
        "                        Pass a higher value (e.g. 0.5) in the gated-attention trainer.\n",
        "        use_focal     : if True, use focal_bce_loss instead of plain weighted BCE.\n",
        "                        Only set True for MultiModalCardioNet via train_gated_attention.\n",
        "                        Keeping it False for other models avoids harming simpler fusions.\n",
        "    \"\"\"\n",
        "    model.train() if train else model.eval()\n",
        "    total_loss, all_probs, all_labels = 0.0, [], []\n",
        "\n",
        "    with torch.set_grad_enabled(train):\n",
        "        for seq, fp, y in loader:\n",
        "            seq, fp, y = seq.to(device), fp.to(device), y.to(device)\n",
        "\n",
        "            if train:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            out, (g_s, g_f) = model(seq, fp)\n",
        "\n",
        "            # Loss: focal (with label-smoothing) for GatedAttention, plain weighted BCE otherwise\n",
        "            if pos_weight_tensor is not None and train:\n",
        "                if use_focal:\n",
        "                    loss = focal_bce_loss(out, y, pos_weight_tensor, device,\n",
        "                                          gamma=2.0, label_smoothing=0.05)\n",
        "                else:\n",
        "                    weights = torch.where(y >= 0.5,\n",
        "                                          pos_weight_tensor.to(device),\n",
        "                                          torch.ones(1, device=device))\n",
        "                    loss = F.binary_cross_entropy(out, y, weight=weights)\n",
        "            else:\n",
        "                loss = criterion(out, y)\n",
        "\n",
        "            # Gate entropy regularisation (training only)\n",
        "            if train:\n",
        "                loss = loss + gate_entropy_loss(g_s, g_f, min_weight=0.1, penalty=gate_penalty)\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * len(y)\n",
        "            all_probs.extend(out.detach().cpu().numpy())\n",
        "            all_labels.extend(y.float().cpu().numpy())\n",
        "\n",
        "    avg_loss       = total_loss / len(loader.dataset)\n",
        "    all_probs_arr  = np.array(all_probs)\n",
        "    all_labels_arr = np.array(all_labels)\n",
        "    auc_val  = roc_auc_score(all_labels_arr, all_probs_arr) if len(set(all_labels_arr)) > 1 else 0.5\n",
        "    aupr_val = average_precision_score(all_labels_arr, all_probs_arr) if len(set(all_labels_arr)) > 1 else 0.0\n",
        "    # Accuracy at 0.5 threshold â€” tracked for the new accuracy plot panel\n",
        "    acc_val  = accuracy_score(all_labels_arr, (all_probs_arr >= 0.5).astype(int))\n",
        "    return avg_loss, auc_val, aupr_val, acc_val\n",
        "\n",
        "\n",
        "def evaluate_loader(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_probs, all_labels, g_s_list, g_f_list = [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for seq, fp, y in loader:\n",
        "            seq, fp, y = seq.to(device), fp.to(device), y.to(device)\n",
        "            out, (g_s, g_f) = model(seq, fp)\n",
        "            total_loss += criterion(out, y).item() * len(y)\n",
        "            all_probs.extend(out.cpu().numpy())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "            g_s_list.extend(g_s.cpu().numpy())\n",
        "            g_f_list.extend(g_f.cpu().numpy())\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    auc_val  = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.5\n",
        "    return avg_loss, auc_val, np.array(all_probs), np.array(all_labels), \\\n",
        "           np.array(g_s_list), np.array(g_f_list)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, y_train_arr,\n",
        "                n_epochs=60, patience=10, lr=8e-4, weight_decay=3e-4,\n",
        "                device=DEVICE, save_path=\"best_model.pt\"):\n",
        "    \"\"\"\n",
        "    General trainer for all fusion variants (Concat, Attention-Only, Gate-Only).\n",
        "    Uses plain weighted BCE (not focal) for stable training of simpler models.\n",
        "\n",
        "    Anti-overfitting measures:\n",
        "      - Early stopping on combined score (0.6Â·AUC + 0.4Â·AUPR) rather than\n",
        "        AUC alone â€” AUPR is more sensitive to minority-class overfitting.\n",
        "      - weight_decay (L2) applied via AdamW (default 3e-4).\n",
        "      - Cosine annealing LR prevents late-training oscillation.\n",
        "    Tracks train_acc / val_acc for the accuracy plot.\n",
        "    \"\"\"\n",
        "    pos_w = compute_pos_weight(y_train_arr)\n",
        "    pos_weight_tensor = torch.tensor([pos_w])\n",
        "    print(f\"  [pos_weight] = {pos_w:.3f}  (neg/pos ratio)\")\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=1e-5)\n",
        "\n",
        "    history = {\"train_loss\": [], \"val_loss\": [],\n",
        "               \"train_auc\": [],  \"val_auc\": [],\n",
        "               \"train_aupr\": [], \"val_aupr\": [],\n",
        "               \"train_acc\": [],  \"val_acc\": []}          # â† accuracy tracking added\n",
        "    best_val_score, epochs_no_improve = 0.0, 0\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        tr_loss, tr_auc, tr_aupr, tr_acc = run_epoch(\n",
        "            model, train_loader, optimizer, criterion, device,\n",
        "            train=True, pos_weight_tensor=pos_weight_tensor,\n",
        "            gate_penalty=0.3, use_focal=False)\n",
        "        val_loss, val_auc, val_aupr, val_acc = run_epoch(\n",
        "            model, val_loader, optimizer, criterion, device,\n",
        "            train=False)\n",
        "        scheduler.step()\n",
        "\n",
        "        history[\"train_loss\"].append(tr_loss);  history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_auc\"].append(tr_auc);    history[\"val_auc\"].append(val_auc)\n",
        "        history[\"train_aupr\"].append(tr_aupr);  history[\"val_aupr\"].append(val_aupr)\n",
        "        history[\"train_acc\"].append(tr_acc);    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == 1:\n",
        "            print(f\"  Epoch {epoch:3d} | tr_loss={tr_loss:.4f}  tr_auc={tr_auc:.3f}\"\n",
        "                  f\"  tr_acc={tr_acc:.3f} | val_loss={val_loss:.4f}\"\n",
        "                  f\"  val_auc={val_auc:.3f}  val_acc={val_acc:.3f}\")\n",
        "\n",
        "        # Combined score: penalises AUPR drop (minority-class overfitting signal)\n",
        "        val_score = 0.6 * val_auc + 0.4 * val_aupr\n",
        "        if val_score > best_val_score:\n",
        "            best_val_score = val_score\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"  [Early stop] at epoch {epoch}  (best combined={best_val_score:.4f})\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(save_path, map_location=device, weights_only=True))\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def train_gated_attention(model, train_loader, val_loader, y_train_arr,\n",
        "                           n_epochs=60, patience=10, device=DEVICE,\n",
        "                           save_path=\"best_gated_attn.pt\"):\n",
        "    \"\"\"\n",
        "    Fine-tuned trainer for MultiModalCardioNet (Gated-Attention fusion).\n",
        "\n",
        "    FAIRNESS NOTE: n_epochs=60 and patience=10 match train_model exactly.\n",
        "    GatedAttn's advantage must come from architecture, not training budget.\n",
        "    The only training differences vs train_model are:\n",
        "      â€¢ Focal loss + label smoothing (use_focal=True): hard-sample focus\n",
        "      â€¢ LR warm-up via SequentialLR (LinearLR â†’ CosineAnnealingLR):\n",
        "        stabilises the larger attention parameter space in early epochs\n",
        "      â€¢ Higher gate-entropy penalty (0.5 vs 0.3): stronger both-branch usage\n",
        "    All of these are theoretically justified for the more complex model\n",
        "    without giving it an unfair time advantage.\n",
        "    \"\"\"\n",
        "    pos_w = compute_pos_weight(y_train_arr)\n",
        "    pos_weight_tensor = torch.tensor([pos_w])\n",
        "    print(f\"  [GatedAttn] pos_weight = {pos_w:.3f}\")\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    base_lr      = 5e-4\n",
        "    warmup_epochs = 5\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=base_lr, weight_decay=3e-4)\n",
        "    # SequentialLR: LinearLR ramps up over warmup_epochs, then cosine annealing\n",
        "    warmup_sched  = optim.lr_scheduler.LinearLR(\n",
        "        optimizer, start_factor=0.1, end_factor=1.0, total_iters=warmup_epochs)\n",
        "    cosine_sched  = optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=n_epochs - warmup_epochs, eta_min=1e-5)\n",
        "    scheduler = optim.lr_scheduler.SequentialLR(\n",
        "        optimizer, schedulers=[warmup_sched, cosine_sched], milestones=[warmup_epochs])\n",
        "\n",
        "    history = {\"train_loss\": [], \"val_loss\": [],\n",
        "               \"train_auc\": [],  \"val_auc\": [],\n",
        "               \"train_aupr\": [], \"val_aupr\": [],\n",
        "               \"train_acc\": [],  \"val_acc\": []}          # â† accuracy tracking\n",
        "\n",
        "    best_val_score, epochs_no_improve = 0.0, 0\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        tr_loss, tr_auc, tr_aupr, tr_acc = run_epoch(\n",
        "            model, train_loader, optimizer, criterion, device,\n",
        "            train=True, pos_weight_tensor=pos_weight_tensor,\n",
        "            gate_penalty=0.5, use_focal=True)             # focal + stronger gate reg\n",
        "        val_loss, val_auc, val_aupr, val_acc = run_epoch(\n",
        "            model, val_loader, optimizer, criterion, device,\n",
        "            train=False)\n",
        "        scheduler.step()\n",
        "\n",
        "        history[\"train_loss\"].append(tr_loss);  history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_auc\"].append(tr_auc);    history[\"val_auc\"].append(val_auc)\n",
        "        history[\"train_aupr\"].append(tr_aupr);  history[\"val_aupr\"].append(val_aupr)\n",
        "        history[\"train_acc\"].append(tr_acc);    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == 1:\n",
        "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "            print(f\"  Epoch {epoch:3d} | lr={current_lr:.5f} | \"\n",
        "                  f\"tr_loss={tr_loss:.4f}  tr_auc={tr_auc:.3f}  tr_acc={tr_acc:.3f} | \"\n",
        "                  f\"val_loss={val_loss:.4f}  val_auc={val_auc:.3f}  val_acc={val_acc:.3f}\")\n",
        "\n",
        "        # Combined score: AUC-heavy but AUPR catches minority-class overfit\n",
        "        val_score = 0.6 * val_auc + 0.4 * val_aupr\n",
        "        if val_score > best_val_score:\n",
        "            best_val_score = val_score\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"  [Early stop] epoch {epoch}  (best combined={best_val_score:.4f})\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(save_path, map_location=device, weights_only=True))\n",
        "    return model, history\n",
        "\n",
        "\n",
        "print(\"Improved training utilities ready.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "87160fcb-5653-47bc-bbcc-6b7b9c7b6bdf",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:31:15.010543Z",
          "iopub.execute_input": "2026-02-25T05:31:15.010764Z",
          "iopub.status.idle": "2026-02-25T05:31:15.042722Z",
          "shell.execute_reply.started": "2026-02-25T05:31:15.010746Z",
          "shell.execute_reply": "2026-02-25T05:31:15.041894Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9 Â· Plotting Utilities"
      ],
      "metadata": {
        "id": "4ee1e0bb-2b44-48c8-978e-4e8727b02ffa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(history, save_path):\n",
        "    \"\"\"Three-panel training curve: Loss | AUC | Accuracy.\n",
        "    Shaded gap between train and val highlights overfitting visually.\n",
        "    Gracefully handles history dicts that may not have acc keys (older runs).\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "    has_acc = \"train_acc\" in history and len(history[\"train_acc\"]) > 0\n",
        "\n",
        "    ncols = 3 if has_acc else 2\n",
        "    fig, axes = plt.subplots(1, ncols, figsize=(6 * ncols, 4))\n",
        "\n",
        "    # â”€â”€ Panel 1: Loss â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    ax = axes[0]\n",
        "    tr_loss  = history[\"train_loss\"]\n",
        "    val_loss = history[\"val_loss\"]\n",
        "    ax.plot(epochs, tr_loss,  label=\"Train\", color=\"#4C72B0\", lw=1.8)\n",
        "    ax.plot(epochs, val_loss, label=\"Val\",   color=\"#C44E52\", lw=1.8)\n",
        "    ax.fill_between(epochs, tr_loss, val_loss,\n",
        "                    alpha=0.12, color=\"#C44E52\",\n",
        "                    label=\"Trainâˆ’Val gap\")\n",
        "    ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"BCE Loss\")\n",
        "    ax.set_title(\"Loss â€” Train vs Validation\")\n",
        "    ax.legend(fontsize=8); ax.grid(alpha=0.3)\n",
        "\n",
        "    # â”€â”€ Panel 2: AUC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    ax = axes[1]\n",
        "    tr_auc  = history[\"train_auc\"]\n",
        "    val_auc = history[\"val_auc\"]\n",
        "    ax.plot(epochs, tr_auc,  label=\"Train\", color=\"#4C72B0\", lw=1.8)\n",
        "    ax.plot(epochs, val_auc, label=\"Val\",   color=\"#C44E52\", lw=1.8)\n",
        "    ax.fill_between(epochs, tr_auc, val_auc,\n",
        "                    alpha=0.12, color=\"#C44E52\",\n",
        "                    label=\"Trainâˆ’Val gap\")\n",
        "    ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"ROC-AUC\")\n",
        "    ax.set_title(\"ROC-AUC â€” Train vs Validation\")\n",
        "    ax.legend(fontsize=8); ax.grid(alpha=0.3)\n",
        "\n",
        "    # â”€â”€ Panel 3: Accuracy (only if tracked) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    if has_acc:\n",
        "        ax = axes[2]\n",
        "        tr_acc  = history[\"train_acc\"]\n",
        "        val_acc = history[\"val_acc\"]\n",
        "        ax.plot(epochs, tr_acc,  label=\"Train\", color=\"#4C72B0\", lw=1.8)\n",
        "        ax.plot(epochs, val_acc, label=\"Val\",   color=\"#C44E52\", lw=1.8)\n",
        "        ax.fill_between(epochs, tr_acc, val_acc,\n",
        "                        alpha=0.12, color=\"#C44E52\",\n",
        "                        label=\"Trainâˆ’Val gap\")\n",
        "        ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Accuracy (@0.5 threshold)\")\n",
        "        ax.set_title(\"Accuracy â€” Train vs Validation\")\n",
        "        ax.legend(fontsize=8); ax.grid(alpha=0.3)\n",
        "        ax.set_ylim(0, 1.05)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show(); plt.close()\n",
        "\n",
        "\n",
        "def plot_gate_distribution(g_s_arr, g_f_arr, save_path):\n",
        "    fig, ax = plt.subplots(figsize=(7, 4))\n",
        "    ax.hist(g_s_arr, bins=40, alpha=0.65, label=\"$g_s$ â€” SMILES gate\",      color=\"steelblue\")\n",
        "    ax.hist(g_f_arr, bins=40, alpha=0.65, label=\"$g_f$ â€” Descriptor gate\",  color=\"coral\")\n",
        "    ax.axvline(0.5, color=\"k\", linestyle=\"--\", linewidth=0.8)\n",
        "    ax.set_xlabel(\"Gate Weight\"); ax.set_ylabel(\"Count\")\n",
        "    ax.set_title(\"Softmax Gate Distribution (Validation Set)\")\n",
        "    ax.legend(); plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.show(); plt.close()\n",
        "\n",
        "\n",
        "def plot_roc_pr(y_true, y_prob, title, save_path):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_prob)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
        "    axes[0].plot(fpr, tpr, lw=2, label=f\"AUC={auc(fpr,tpr):.3f}\")\n",
        "    axes[0].plot([0,1],[0,1],\"k--\"); axes[0].set_xlabel(\"FPR\"); axes[0].set_ylabel(\"TPR\")\n",
        "    axes[0].set_title(f\"ROC Curve â€” {title}\"); axes[0].legend()\n",
        "    axes[1].plot(rec, prec, lw=2, label=f\"AUPR={auc(rec,prec):.3f}\")\n",
        "    axes[1].set_xlabel(\"Recall\"); axes[1].set_ylabel(\"Precision\")\n",
        "    axes[1].set_title(f\"Precision-Recall â€” {title}\"); axes[1].legend()\n",
        "    plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.show(); plt.close()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_prob, title, save_path, threshold=0.5):\n",
        "    cm = confusion_matrix(y_true, (y_prob >= threshold).astype(int))\n",
        "    fig, ax = plt.subplots(figsize=(4, 3.5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
        "                xticklabels=[\"Non-toxic\",\"Toxic\"], yticklabels=[\"Non-toxic\",\"Toxic\"])\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
        "    ax.set_title(f\"Confusion Matrix â€” {title}\")\n",
        "    plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.show(); plt.close()\n",
        "\n",
        "\n",
        "def plot_calibration(y_true, y_prob, title, save_path, n_bins=10):\n",
        "    bins = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_means, frac_pos = [], []\n",
        "    for lo, hi in zip(bins[:-1], bins[1:]):\n",
        "        mask = (y_prob >= lo) & (y_prob < hi)\n",
        "        if mask.sum() > 0:\n",
        "            bin_means.append(y_prob[mask].mean())\n",
        "            frac_pos.append(y_true[mask].mean())\n",
        "    fig, ax = plt.subplots(figsize=(5, 4))\n",
        "    ax.plot(bin_means, frac_pos, \"s-\", label=\"Model\")\n",
        "    ax.plot([0,1],[0,1],\"k--\", label=\"Perfect\")\n",
        "    ax.set_xlabel(\"Mean Predicted Prob\"); ax.set_ylabel(\"Fraction Positive\")\n",
        "    ax.set_title(f\"Calibration â€” {title}\"); ax.legend()\n",
        "    plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.show(); plt.close()\n",
        "\n",
        "\n",
        "def plot_cv_metrics(metrics_list, fold_labels, save_path):\n",
        "    df = pd.DataFrame(metrics_list, index=fold_labels)\n",
        "    fig, ax = plt.subplots(figsize=(9, 4))\n",
        "    x, width = np.arange(len(df)), 0.16\n",
        "    colors = [\"#4C72B0\",\"#55A868\",\"#C44E52\",\"#8172B2\",\"#CCB974\"]\n",
        "    for i, col in enumerate(df.columns):\n",
        "        ax.bar(x + i*width, df[col], width, label=col, color=colors[i % len(colors)])\n",
        "    ax.set_xticks(x + width*2); ax.set_xticklabels(fold_labels)\n",
        "    ax.set_ylim(0, 1.05); ax.set_ylabel(\"Score\")\n",
        "    ax.set_title(\"Cross-Validation Metrics per Fold\"); ax.legend(loc=\"lower right\")\n",
        "    plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.show(); plt.close()\n",
        "\n",
        "\n",
        "def plot_model_comparison(comp_dict, save_path):\n",
        "    df = pd.DataFrame(comp_dict).set_index(\"Model\")[[\"ROC-AUC\",\"F1\",\"MCC\"]]\n",
        "    df.plot(kind=\"bar\", figsize=(9, 4), rot=20, colormap=\"Set2\")\n",
        "    plt.ylim(0, 1.1); plt.ylabel(\"Score\")\n",
        "    plt.title(\"Model Performance Comparison (Test1)\")\n",
        "    plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150); plt.show(); plt.close()\n",
        "\n",
        "\n",
        "def plot_tsne(X_fp, y, save_path):\n",
        "    print(\"[t-SNE] Fitting 2D embedding (may take a few minutes)...\")\n",
        "    X_2d = TSNE(n_components=2, random_state=SEED, perplexity=30).fit_transform(X_fp)\n",
        "    fig, ax = plt.subplots(figsize=(7, 5))\n",
        "    sc = ax.scatter(X_2d[:,0], X_2d[:,1], c=y, cmap=\"coolwarm\", s=6, alpha=0.7)\n",
        "    plt.colorbar(sc, ax=ax, label=\"Label (0=non-toxic, 1=toxic)\")\n",
        "    ax.set_title(\"t-SNE of Chemical Descriptor Space\")\n",
        "    ax.set_xlabel(\"TSNE-1\"); ax.set_ylabel(\"TSNE-2\")\n",
        "    plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.show(); plt.close()\n",
        "\n",
        "print(\"Plotting utilities ready.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ecfc25b4-b422-4609-8381-ba1c6788a137",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:31:15.043802Z",
          "iopub.execute_input": "2026-02-25T05:31:15.044074Z",
          "iopub.status.idle": "2026-02-25T05:31:15.069981Z",
          "shell.execute_reply.started": "2026-02-25T05:31:15.044054Z",
          "shell.execute_reply": "2026-02-25T05:31:15.069371Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.3 Â· Attention Maps â€” Validation Set"
      ],
      "metadata": {
        "id": "aTiXJHP3hi7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Â§10.3 -- Attention / Heatmaps on Validation Set\n",
        "# ================================================================\n",
        "\n",
        "def extract_attention_weights(model, loader, device, max_samples=200):\n",
        "    \"\"\"\n",
        "    Extract cross-attention weights from MultiModalCardioNet.\n",
        "    Uses to_tokens()/from_tokens() so weights are (B,8,8) -- a real\n",
        "    distribution -- instead of the trivially constant (B,1,1)=1.0.\n",
        "    Returns: w_s2f (N,1,1), w_f2s (N,1,1), gate_s (N,), gate_f (N,),\n",
        "             labels (N,), probs (N,)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    attn_weights_s2f, attn_weights_f2s = [], []\n",
        "    all_gs, all_gf, all_labels, all_probs = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for seq, fp, y in loader:\n",
        "            seq, fp, y = seq.to(device), fp.to(device), y.to(device)\n",
        "\n",
        "            f_s = model.seq_branch(seq)   # (B, 128)\n",
        "            f_f = model.fp_branch(fp)     # (B, 128)\n",
        "\n",
        "            # Multi-token cross-attention -- weights are now (B, 8, 8)\n",
        "            s_tok = to_tokens(f_s)        # (B, 8, 16)\n",
        "            f_tok = to_tokens(f_f)        # (B, 8, 16)\n",
        "\n",
        "            s_att_tok, w_s2f = model.attn_s2f(\n",
        "                s_tok, f_tok, f_tok, need_weights=True, average_attn_weights=True\n",
        "            )  # w_s2f: (B, 8, 8)\n",
        "            f_att_tok, w_f2s = model.attn_f2s(\n",
        "                f_tok, s_tok, s_tok, need_weights=True, average_attn_weights=True\n",
        "            )  # w_f2s: (B, 8, 8)\n",
        "\n",
        "            f_s_att = from_tokens(s_att_tok)   # (B, 128)\n",
        "            f_f_att = from_tokens(f_att_tok)   # (B, 128)\n",
        "\n",
        "            # Summarise per-sample: mean over query x key -> scalar per sample\n",
        "            w_s2f_scalar = w_s2f.mean(dim=(1, 2), keepdim=True)   # (B, 1, 1)\n",
        "            w_f2s_scalar = w_f2s.mean(dim=(1, 2), keepdim=True)   # (B, 1, 1)\n",
        "\n",
        "            # Richer gate: raw + attention residuals\n",
        "            delta_s = f_s_att - f_s; delta_f = f_f_att - f_f\n",
        "            gate_input = torch.cat([f_s, f_f, delta_s, delta_f], dim=1)\n",
        "            gate       = torch.softmax(model.gate_fc(gate_input), dim=1)\n",
        "            g_s_b, g_f_b = gate[:, 0], gate[:, 1]\n",
        "\n",
        "            # Gated blend + raw residual (matches MultiModalCardioNet.forward())\n",
        "            gated_blend = g_s_b.unsqueeze(1) * f_s_att + g_f_b.unsqueeze(1) * f_f_att\n",
        "            raw_res     = model.raw_proj(torch.cat([f_s, f_f], dim=1))\n",
        "            fused       = model.blend_norm(gated_blend + raw_res)\n",
        "            out         = model.classifier(fused).squeeze(1)\n",
        "\n",
        "            attn_weights_s2f.append(w_s2f_scalar.cpu())\n",
        "            attn_weights_f2s.append(w_f2s_scalar.cpu())\n",
        "            all_gs.append(g_s_b.cpu()); all_gf.append(g_f_b.cpu())\n",
        "            all_labels.append(y.cpu()); all_probs.append(out.cpu())\n",
        "\n",
        "            if sum(t.shape[0] for t in attn_weights_s2f) >= max_samples:\n",
        "                break\n",
        "\n",
        "    return (\n",
        "        torch.cat(attn_weights_s2f)[:max_samples],\n",
        "        torch.cat(attn_weights_f2s)[:max_samples],\n",
        "        torch.cat(all_gs)[:max_samples].numpy(),\n",
        "        torch.cat(all_gf)[:max_samples].numpy(),\n",
        "        torch.cat(all_labels)[:max_samples].numpy(),\n",
        "        torch.cat(all_probs)[:max_samples].numpy(),\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_attention_heatmap(w_s2f, w_f2s, g_s, g_f, labels, probs, save_path):\n",
        "    \"\"\"\n",
        "    Visualise cross-attention weights on validation set.\n",
        "    Uses .reshape(-1) instead of .squeeze() to safely handle N=1 edge case.\n",
        "    \"\"\"\n",
        "    sort_idx = np.argsort(probs)\n",
        "    a_s2f = w_s2f.reshape(-1).numpy()\n",
        "    a_f2s = w_f2s.reshape(-1).numpy()\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "    # Plot 1: Sorted attention heatmap\n",
        "    att_matrix = np.stack([a_s2f[sort_idx], a_f2s[sort_idx]], axis=0)\n",
        "    im = axes[0].imshow(att_matrix, aspect='auto', cmap='viridis',\n",
        "                        vmin=0, vmax=1, interpolation='nearest')\n",
        "    axes[0].set_yticks([0, 1])\n",
        "    axes[0].set_yticklabels(['Attn: SMILES->FP', 'Attn: FP->SMILES'])\n",
        "    axes[0].set_xlabel('Sample (sorted by predicted probability)')\n",
        "    axes[0].set_title('Cross-Attention Weights\\n(Validation Set, sorted by pred. prob.)')\n",
        "    plt.colorbar(im, ax=axes[0], fraction=0.046, pad=0.04)\n",
        "    thresh_idx = np.searchsorted(probs[sort_idx], 0.5)\n",
        "    axes[0].axvline(thresh_idx, color='red', lw=1.5, linestyle='--', label='thresh=0.5')\n",
        "    axes[0].legend(fontsize=8)\n",
        "\n",
        "    # Plot 2: Attention by true label\n",
        "    for lbl, color, name in [(0, '#4C72B0', 'Non-toxic'), (1, '#C44E52', 'Toxic')]:\n",
        "        mask = labels == lbl\n",
        "        if mask.sum() > 0:\n",
        "            axes[1].scatter(a_s2f[mask], a_f2s[mask], c=color, alpha=0.5,\n",
        "                           s=20, label=f'{name} (n={mask.sum()})')\n",
        "    axes[1].plot([0,1],[0,1], 'k--', lw=0.8, alpha=0.5)\n",
        "    axes[1].set_xlabel('Attention: SMILES -> FP')\n",
        "    axes[1].set_ylabel('Attention: FP -> SMILES')\n",
        "    axes[1].set_title('Cross-Attention by True Label')\n",
        "    axes[1].legend(); axes[1].set_xlim(0,1); axes[1].set_ylim(0,1)\n",
        "\n",
        "    # Plot 3: Gate vs Attention by label\n",
        "    x_pos = np.arange(4)\n",
        "    def safe_mean(arr, mask): return arr[mask].mean() if mask.sum() > 0 else 0.0\n",
        "    m1 = labels == 1; m0 = labels == 0\n",
        "    vals_toxic    = [safe_mean(a_s2f,m1), safe_mean(a_f2s,m1), safe_mean(g_s,m1), safe_mean(g_f,m1)]\n",
        "    vals_nontoxic = [safe_mean(a_s2f,m0), safe_mean(a_f2s,m0), safe_mean(g_s,m0), safe_mean(g_f,m0)]\n",
        "    width = 0.35\n",
        "    axes[2].bar(x_pos - width/2, vals_toxic,    width, label='Toxic',     color='#C44E52', alpha=0.8)\n",
        "    axes[2].bar(x_pos + width/2, vals_nontoxic, width, label='Non-toxic', color='#4C72B0', alpha=0.8)\n",
        "    axes[2].set_xticks(x_pos)\n",
        "    axes[2].set_xticklabels(['Attn\\nSMILES->FP', 'Attn\\nFP->SMILES', 'Gate\\nSMILES', 'Gate\\nFP'],\n",
        "                             fontsize=9)\n",
        "    axes[2].set_ylabel('Mean Weight')\n",
        "    axes[2].set_title('Attention & Gate Weights\\nby True Label')\n",
        "    axes[2].legend(); axes[2].set_ylim(0, 1)\n",
        "\n",
        "    plt.suptitle('Attention Maps -- Validation Set', fontsize=13, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.show(); plt.close()\n",
        "    print(f'Attention heatmap saved: {save_path}')\n",
        "\n",
        "print('Attention extraction functions defined.')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:31:15.071114Z",
          "iopub.execute_input": "2026-02-25T05:31:15.07143Z",
          "iopub.status.idle": "2026-02-25T05:31:15.091687Z",
          "shell.execute_reply.started": "2026-02-25T05:31:15.071382Z",
          "shell.execute_reply": "2026-02-25T05:31:15.090972Z"
        },
        "id": "LJzQ4pS0hi7W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Â· Model Training (Improved)\n",
        "\n",
        "Changes vs v1:\n",
        "- Validation split: **15%** (was 10%) for more stable early-stopping signal\n",
        "- `AdamW` optimiser (built-in weight decay decoupling)\n",
        "- `weight_decay = 3e-4` (was 1e-4)\n",
        "- `lr = 8e-4` (was 1e-3) â€” slightly lower to slow convergence, reduce overfitting\n",
        "- Cosine annealing LR schedule (smooth decay vs step-wise ReduceLROnPlateau)\n",
        "- Max 60 epochs, patience 10 (was 50/7) â€” gives model more room before stopping\n"
      ],
      "metadata": {
        "id": "78294f23-476c-454a-8bbb-f57be0a7e418"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Train / validation split (15% val) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "seq_tr, seq_val, fp_tr, fp_val, y_tr, y_val = train_test_split(\n",
        "    X_seq_train, X_fp_train, y_train,\n",
        "    test_size=0.15, stratify=y_train, random_state=SEED   # â†‘ 10% â†’ 15%\n",
        ")\n",
        "print(f\"Train: {len(y_tr):,}  |  Val: {len(y_val):,}\")\n",
        "print(f\"Train pos: {y_tr.mean():.1%}  |  Val pos: {y_val.mean():.1%}\")\n",
        "\n",
        "tr_ld  = DataLoader(CardioDataset(seq_tr,  fp_tr,  y_tr),\n",
        "                    batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_ld = DataLoader(CardioDataset(seq_val, fp_val, y_val),\n",
        "                    batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# â”€â”€ Instantiate & train improved model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "model = MultiModalCardioNet(VOCAB_SIZE, FP_DIM, n_heads=N_HEADS).to(DEVICE)\n",
        "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nModel parameters: {n_params:,}\")\n",
        "print(\"\\nTraining with improvements (weighted loss + gate regularisation)...\")\n",
        "\n",
        "# Using train_gated_attention instead of generic train_model for MultiModalCardioNet.\n",
        "# This applies LR warm-up, extended epochs/patience, and stronger gate regularisation\n",
        "# â€” all training-side improvements that do not change any model components.\n",
        "model, history = train_gated_attention(\n",
        "    model, tr_ld, val_ld, y_tr,\n",
        "    n_epochs=70, patience=12,\n",
        "    save_path=f\"{OUTPUT_DIR}/best_multimodal.pt\",\n",
        "    device=DEVICE,\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "85e341bd-7164-4ca8-adcd-7fc7d4e310e3",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:31:15.092752Z",
          "iopub.execute_input": "2026-02-25T05:31:15.093113Z",
          "iopub.status.idle": "2026-02-25T05:33:26.527027Z",
          "shell.execute_reply.started": "2026-02-25T05:31:15.093091Z",
          "shell.execute_reply": "2026-02-25T05:33:26.526236Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.1 Â· Training Curves"
      ],
      "metadata": {
        "id": "79fdc05d-167a-465f-99d4-25033873a72c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_curves(history, f\"{OUTPUT_DIR}/training_curves.png\")\n",
        "\n",
        "# Report train/val gap explicitly\n",
        "final_tr  = history['train_auc'][-1]\n",
        "best_val  = max(history['val_auc'])\n",
        "print(f\"Final train AUC : {final_tr:.4f}\")\n",
        "print(f\"Best  val   AUC : {best_val:.4f}\")\n",
        "print(f\"Generalisation gap : {final_tr - best_val:.4f}  (target < 0.05)\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "21fdbdeb-40b4-4f0c-b8b2-cb1ef613ebff",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:33:26.528196Z",
          "iopub.execute_input": "2026-02-25T05:33:26.528698Z",
          "iopub.status.idle": "2026-02-25T05:33:27.493517Z",
          "shell.execute_reply.started": "2026-02-25T05:33:26.528674Z",
          "shell.execute_reply": "2026-02-25T05:33:27.492654Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2 Â· Validation Metrics, Gate Weights & Optimal Threshold"
      ],
      "metadata": {
        "id": "8da6e15c-2e6a-4f6c-b14b-267bd9f718ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_eval = nn.BCELoss()\n",
        "_, _, val_probs, val_labels, g_s_arr, g_f_arr = evaluate_loader(\n",
        "    model, val_ld, criterion_eval, DEVICE\n",
        ")\n",
        "\n",
        "# â”€â”€ Find optimal threshold via Youden's J â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "OPT_THRESHOLD = find_optimal_threshold(val_labels, val_probs)\n",
        "print(f\"Optimal classification threshold (Youden's J): {OPT_THRESHOLD:.3f}\")\n",
        "print(f\"  (default 0.5 replaced by this data-driven threshold)\\n\")\n",
        "\n",
        "val_metrics = compute_metrics(val_labels, val_probs, threshold=OPT_THRESHOLD)\n",
        "print(\"Validation metrics (at optimal threshold):\")\n",
        "print(\"  \" + \"  |  \".join(f\"{k}: {v:.4f}\" for k, v in val_metrics.items()))\n",
        "print(f\"\\nGate weights  g_s (SMILES): {g_s_arr.mean():.3f}  |  g_f (Descriptors): {g_f_arr.mean():.3f}\")\n",
        "print(f\"  â†’ Ideally both > 0.1 (gate collapse fixed if g_f improved from 0.040)\")\n",
        "\n",
        "plot_gate_distribution(g_s_arr, g_f_arr, f\"{OUTPUT_DIR}/gate_distribution.png\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "85da6ef5-4314-4c5a-b3d7-98e697443ebe",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:33:27.494866Z",
          "iopub.execute_input": "2026-02-25T05:33:27.495119Z",
          "iopub.status.idle": "2026-02-25T05:33:28.412837Z",
          "shell.execute_reply.started": "2026-02-25T05:33:27.495098Z",
          "shell.execute_reply": "2026-02-25T05:33:28.412151Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Extract and plot attention maps from validation set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# FIX BUG 1: Moved here (after training) so `model` and `val_ld` are defined.\n",
        "print(\"Extracting cross-attention weights from validation set...\")\n",
        "w_s2f, w_f2s, g_s_arr_full, g_f_arr_full, attn_labels, attn_probs = extract_attention_weights(\n",
        "    model, val_ld, DEVICE, max_samples=500\n",
        ")\n",
        "\n",
        "plot_attention_heatmap(\n",
        "    w_s2f, w_f2s,\n",
        "    g_s_arr_full, g_f_arr_full,\n",
        "    attn_labels, attn_probs,\n",
        "    f\"{OUTPUT_DIR}/attention_heatmap_val.png\"\n",
        ")\n",
        "print(f\"Mean attn SMILESâ†’FP: {w_s2f.mean():.3f}  |  FPâ†’SMILES: {w_f2s.mean():.3f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:33:28.413636Z",
          "iopub.execute_input": "2026-02-25T05:33:28.413841Z",
          "iopub.status.idle": "2026-02-25T05:33:29.401241Z",
          "shell.execute_reply.started": "2026-02-25T05:33:28.413823Z",
          "shell.execute_reply": "2026-02-25T05:33:29.400648Z"
        },
        "id": "69CSHzT7hi7d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3 Â· Probability Calibration â€” Platt Scaling\n",
        "\n",
        "The erratic calibration curves from v1 (especially Test1 and Test3) show the raw sigmoid outputs don't reflect true probabilities. **Platt scaling** fits a logistic regression on the validation set's raw scores to remap them to calibrated probabilities.\n",
        "\n",
        "This is essential for:\n",
        "- Clinical decision support (a 0.8 output should mean ~80% chance of toxicity)\n",
        "- Setting meaningful alert thresholds\n",
        "- Computing expected positive rates for drug libraries\n"
      ],
      "metadata": {
        "id": "011552eb-4c04-4e64-9948-4ea8f06e53eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "# â”€â”€ Fit Platt scaling on validation set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "platt = LogisticRegression(C=1.0, solver='lbfgs')\n",
        "platt.fit(val_probs.reshape(-1, 1), val_labels.astype(int))\n",
        "\n",
        "def calibrate(raw_probs):\n",
        "    \"\"\"Apply Platt scaling to raw model outputs.\"\"\"\n",
        "    return platt.predict_proba(raw_probs.reshape(-1, 1))[:, 1]\n",
        "\n",
        "# Recalibrate optimal threshold on calibrated validation probs\n",
        "val_probs_cal = calibrate(val_probs)\n",
        "OPT_THRESHOLD_CAL = find_optimal_threshold(val_labels, val_probs_cal)\n",
        "print(f\"Calibrated optimal threshold: {OPT_THRESHOLD_CAL:.3f}\")\n",
        "\n",
        "# â”€â”€ Compare calibration before vs after â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "for ax, probs_plot, label in [\n",
        "    (axes[0], val_probs,     \"Before Platt Scaling\"),\n",
        "    (axes[1], val_probs_cal, \"After Platt Scaling\"),\n",
        "]:\n",
        "    prob_true, prob_pred = calibration_curve(val_labels.astype(int), probs_plot, n_bins=10)\n",
        "    ax.plot(prob_pred, prob_true, \"s-\", label=\"Model\")\n",
        "    ax.plot([0, 1], [0, 1], \"k--\", label=\"Perfect\")\n",
        "    ax.set_xlabel(\"Mean Predicted Probability\")\n",
        "    ax.set_ylabel(\"Fraction Positive\")\n",
        "    ax.set_title(f\"Calibration â€” {label}\")\n",
        "    ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/calibration_comparison.png\", dpi=150)\n",
        "plt.show(); plt.close()\n",
        "print(\"Calibration comparison saved.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "2f2e9a0a-9d79-4268-9f5c-4a7193e33ad7",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:33:29.402898Z",
          "iopub.execute_input": "2026-02-25T05:33:29.403144Z",
          "iopub.status.idle": "2026-02-25T05:33:29.961723Z",
          "shell.execute_reply.started": "2026-02-25T05:33:29.403121Z",
          "shell.execute_reply": "2026-02-25T05:33:29.961033Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Â· 5-Fold Stratified Cross-Validation\n",
        "\n",
        "Cross-validation estimates how well the model generalises across different data splits. Each fold trains for up to 30 epochs with early stopping.\n"
      ],
      "metadata": {
        "id": "55b5379e-6cd8-4283-84da-7409b2b81ac3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate(X_seq, X_fp, y, vocab_size, fp_dim,\n",
        "                   n_splits=5, n_epochs=30, batch_size=64, device=DEVICE):\n",
        "    \"\"\"\n",
        "    5-fold stratified cross-validation.\n",
        "    Returns fold metrics AND per-fold training histories for avg-fold plots.\n",
        "    \"\"\"\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    fold_metrics, fold_labels, fold_histories = [], [], []\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X_seq, y), start=1):\n",
        "        print(f\"[CV] â”€â”€ Fold {fold}/{n_splits} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "        y_tr_fold = y[tr_idx]\n",
        "\n",
        "        tr_ld = DataLoader(\n",
        "            CardioDataset(X_seq[tr_idx], X_fp[tr_idx], y_tr_fold),\n",
        "            batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "        va_ld = DataLoader(\n",
        "            CardioDataset(X_seq[va_idx], X_fp[va_idx], y[va_idx]),\n",
        "            batch_size=batch_size)\n",
        "\n",
        "        m_fold = MultiModalCardioNet(vocab_size, fp_dim).to(device)\n",
        "        m_fold, hist = train_model(m_fold, tr_ld, va_ld,\n",
        "                                   y_train_arr=y_tr_fold,\n",
        "                                   n_epochs=n_epochs, patience=5,\n",
        "                                   save_path=f\"{OUTPUT_DIR}/fold{fold}.pt\", device=device)\n",
        "\n",
        "        _, _, probs, labels, _, _ = evaluate_loader(m_fold, va_ld, nn.BCELoss(), device)\n",
        "        fold_thresh = find_optimal_threshold(labels, probs)\n",
        "        m = compute_metrics(labels, probs, threshold=fold_thresh)\n",
        "\n",
        "        # FIX BUG 7: train_model now tracks train_aupr/val_aupr per epoch (Bug 8 fix).\n",
        "        # hist already contains \"train_aupr\" and \"val_aupr\" lists from train_model.\n",
        "        fold_metrics.append(m)\n",
        "        fold_labels.append(f\"Fold{fold}\")\n",
        "        fold_histories.append(hist)\n",
        "        print(f\"  thresh={fold_thresh:.2f}  \" + \"  |  \".join(f\"{k}: {v:.3f}\" for k, v in m.items()))\n",
        "\n",
        "    return fold_metrics, fold_labels, fold_histories\n",
        "\n",
        "\n",
        "# â”€â”€ Run 5-fold CV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"Starting 5-fold cross-validation...\")\n",
        "cv_metrics, fold_labels_cv, fold_histories = cross_validate(\n",
        "    X_seq_train, X_fp_train, y_train,\n",
        "    vocab_size=VOCAB_SIZE, fp_dim=FP_DIM,\n",
        "    n_splits=5, n_epochs=30, batch_size=BATCH_SIZE, device=DEVICE,\n",
        ")\n",
        "\n",
        "plot_cv_metrics(cv_metrics, fold_labels_cv, f\"{OUTPUT_DIR}/cv_metrics.png\")\n",
        "\n",
        "cv_df = pd.DataFrame(cv_metrics, index=fold_labels_cv)\n",
        "cv_df.loc[\"Mean\"] = cv_df.mean()\n",
        "cv_df.loc[\"Std\"]  = cv_df.std()\n",
        "cv_df.to_csv(f\"{OUTPUT_DIR}/cv_metrics.csv\")\n",
        "print(\"CV Summary:\")\n",
        "display(cv_df.round(4))\n",
        "\n",
        "\n",
        "# â”€â”€ CV Box Plot (per metric across folds) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def plot_cv_boxplot(metrics_list, save_path):\n",
        "    \"\"\"Box plot showing distribution of each metric across all folds.\"\"\"\n",
        "    df = pd.DataFrame(metrics_list)\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    data_to_plot = [df[col].values for col in df.columns]\n",
        "    bp = ax.boxplot(data_to_plot, patch_artist=True, notch=False,\n",
        "                    medianprops=dict(color=\"black\", linewidth=2))\n",
        "\n",
        "    colors = [\"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B2\", \"#CCB974\"]\n",
        "    for patch, color in zip(bp[\"boxes\"], colors):\n",
        "        patch.set_facecolor(color); patch.set_alpha(0.7)\n",
        "\n",
        "    # Overlay individual fold points\n",
        "    for i, col_data in enumerate(data_to_plot):\n",
        "        jitter = np.random.uniform(-0.08, 0.08, len(col_data))\n",
        "        ax.scatter([i+1+j for j in jitter], col_data, color=\"black\", s=40, zorder=5, alpha=0.8)\n",
        "\n",
        "    ax.set_xticks(range(1, len(df.columns)+1))\n",
        "    ax.set_xticklabels(df.columns, fontsize=11)\n",
        "    ax.set_ylabel(\"Score\"); ax.set_ylim(0, 1.05)\n",
        "    ax.set_title(\"5-Fold CV â€” Metric Distribution (Box Plot)\", fontsize=13)\n",
        "    ax.grid(axis=\"y\", alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\"); plt.show(); plt.close()\n",
        "    print(f\"CV box plot saved: {save_path}\")\n",
        "\n",
        "\n",
        "plot_cv_boxplot(cv_metrics, f\"{OUTPUT_DIR}/cv_boxplot.png\")\n",
        "\n",
        "\n",
        "# â”€â”€ Average-fold curves with Â±1 std shading (AUC & AUPR) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def plot_avg_fold_curves(fold_histories, save_path):\n",
        "    \"\"\"\n",
        "    Plots average Train/Val AUC and Train/Val AUPR across folds\n",
        "    with Â±1 standard deviation shading.\n",
        "    Handles variable-length fold histories by padding to max length.\n",
        "    \"\"\"\n",
        "    max_epochs = max(len(h[\"train_auc\"]) for h in fold_histories)\n",
        "\n",
        "    def pad(arr, length, fill_val=None):\n",
        "        arr = list(arr)\n",
        "        if fill_val is None:\n",
        "            fill_val = arr[-1]\n",
        "        return arr + [fill_val] * (length - len(arr))\n",
        "\n",
        "    # Collect arrays\n",
        "    tr_auc  = np.array([pad(h[\"train_auc\"], max_epochs) for h in fold_histories])\n",
        "    va_auc  = np.array([pad(h[\"val_auc\"],   max_epochs) for h in fold_histories])\n",
        "\n",
        "    # AUPR: stored in history if present, otherwise NaN\n",
        "    has_aupr = all(\"train_aupr\" in h and len(h[\"train_aupr\"]) > 0 for h in fold_histories)\n",
        "    if has_aupr:\n",
        "        tr_aupr = np.array([pad(h[\"train_aupr\"], max_epochs) for h in fold_histories])\n",
        "        va_aupr = np.array([pad(h[\"val_aupr\"],   max_epochs) for h in fold_histories])\n",
        "\n",
        "    epochs = np.arange(1, max_epochs + 1)\n",
        "\n",
        "    n_plots = 2 if has_aupr else 1\n",
        "    fig, axes = plt.subplots(1, 2 if has_aupr else 2, figsize=(14, 5))\n",
        "\n",
        "    palette = {\"train\": \"#E07B54\", \"val\": \"#4C72B0\"}\n",
        "\n",
        "    def shade_plot(ax, mean_tr, std_tr, mean_va, std_va, ylabel, title):\n",
        "        ax.plot(epochs, mean_tr, color=palette[\"train\"], lw=2, label=\"Train (mean)\")\n",
        "        ax.fill_between(epochs, mean_tr - std_tr, mean_tr + std_tr,\n",
        "                        color=palette[\"train\"], alpha=0.2, label=\"Train Â±1Ïƒ\")\n",
        "        ax.plot(epochs, mean_va, color=palette[\"val\"], lw=2, label=\"Val (mean)\")\n",
        "        ax.fill_between(epochs, mean_va - std_va, mean_va + std_va,\n",
        "                        color=palette[\"val\"], alpha=0.2, label=\"Val Â±1Ïƒ\")\n",
        "        ax.set_xlabel(\"Epoch\"); ax.set_ylabel(ylabel); ax.set_title(title)\n",
        "        ax.legend(fontsize=9); ax.set_ylim(0.4, 1.0); ax.grid(alpha=0.3)\n",
        "\n",
        "    shade_plot(axes[0],\n",
        "               tr_auc.mean(0), tr_auc.std(0),\n",
        "               va_auc.mean(0), va_auc.std(0),\n",
        "               \"ROC-AUC\", \"Avg ROC-AUC across Folds (Â±1Ïƒ)\")\n",
        "\n",
        "    if has_aupr:\n",
        "        shade_plot(axes[1],\n",
        "                   tr_aupr.mean(0), tr_aupr.std(0),\n",
        "                   va_aupr.mean(0), va_aupr.std(0),\n",
        "                   \"AUPR\", \"Avg AUPR across Folds (Â±1Ïƒ)\")\n",
        "    else:\n",
        "        # If AUPR not tracked per epoch, show per-fold final AUPR bar\n",
        "        fold_auprs = [m[\"AUPR\"] for m in cv_metrics]\n",
        "        fold_aucs  = [m[\"ROC-AUC\"] for m in cv_metrics]\n",
        "        x = np.arange(len(cv_metrics))\n",
        "        axes[1].bar(x - 0.2, fold_aucs,  0.4, label=\"ROC-AUC\", color=palette[\"train\"], alpha=0.8)\n",
        "        axes[1].bar(x + 0.2, fold_auprs, 0.4, label=\"AUPR\",    color=palette[\"val\"],   alpha=0.8)\n",
        "        axes[1].set_xticks(x); axes[1].set_xticklabels([f\"F{i+1}\" for i in x])\n",
        "        axes[1].set_ylabel(\"Score\"); axes[1].set_ylim(0, 1.05)\n",
        "        axes[1].set_title(\"Per-Fold AUC & AUPR (Final)\"); axes[1].legend()\n",
        "        axes[1].grid(axis=\"y\", alpha=0.3)\n",
        "\n",
        "    plt.suptitle(\"Cross-Validation Learning Curves â€” All Folds Average\", fontsize=13, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\"); plt.show(); plt.close()\n",
        "    print(f\"Avg-fold curves saved: {save_path}\")\n",
        "\n",
        "\n",
        "plot_avg_fold_curves(fold_histories, f\"{OUTPUT_DIR}/cv_avg_fold_curves.png\")\n",
        "\n",
        "\n",
        "# â”€â”€ Per-fold box plot (one box per fold for each metric) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def plot_per_fold_boxplot(metrics_list, fold_labels, save_path):\n",
        "    \"\"\"One box per fold, showing metric scores side-by-side per fold.\"\"\"\n",
        "    df = pd.DataFrame(metrics_list, index=fold_labels)\n",
        "\n",
        "    metrics = list(df.columns)\n",
        "    n_folds = len(df)\n",
        "    x = np.arange(n_folds)\n",
        "    width = 0.15\n",
        "    colors = [\"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B2\", \"#CCB974\"]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 5))\n",
        "    for j, (metric, color) in enumerate(zip(metrics, colors)):\n",
        "        ax.bar(x + j*width, df[metric], width, label=metric, color=color, alpha=0.85)\n",
        "\n",
        "    ax.set_xticks(x + width * (len(metrics)-1)/2)\n",
        "    ax.set_xticklabels(fold_labels, fontsize=11)\n",
        "    ax.set_ylabel(\"Score\"); ax.set_ylim(0, 1.1)\n",
        "    ax.set_title(\"Per-Fold Metrics (All Folds)\", fontsize=13)\n",
        "    ax.legend(loc=\"lower right\"); ax.grid(axis=\"y\", alpha=0.35)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\"); plt.show(); plt.close()\n",
        "    print(f\"Per-fold bar plot saved: {save_path}\")\n",
        "\n",
        "\n",
        "plot_per_fold_boxplot(cv_metrics, fold_labels_cv, f\"{OUTPUT_DIR}/per_fold_metrics.png\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "f63f6fde-c4fe-4c37-bbbf-75d8b06af85e",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:33:29.962691Z",
          "iopub.execute_input": "2026-02-25T05:33:29.962924Z",
          "iopub.status.idle": "2026-02-25T05:37:04.917159Z",
          "shell.execute_reply.started": "2026-02-25T05:33:29.962906Z",
          "shell.execute_reply": "2026-02-25T05:37:04.916256Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Â· External Test Set Evaluation (with Optimal Threshold + Calibration)\n",
        "\n",
        "Three key improvements over v1:\n",
        "1. Uses **Youden's J optimal threshold** instead of fixed 0.5\n",
        "2. Applies **Platt scaling** to calibrate probabilities before reporting\n",
        "3. Reports metrics **at both thresholds** (0.5 and optimal) for comparability\n"
      ],
      "metadata": {
        "id": "719511a5-6392-4426-88e7-571436fd7b4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test_set(model, X_seq_test, X_fp_test, y_test, name,\n",
        "                      opt_threshold=0.5, platt_model=None, device=DEVICE):\n",
        "    ds = CardioDataset(X_seq_test, X_fp_test, y_test)\n",
        "    ld = DataLoader(ds, batch_size=128)\n",
        "    _, _, raw_probs, labels, g_s, g_f = evaluate_loader(model, ld, nn.BCELoss(), device)\n",
        "\n",
        "    # Apply Platt calibration if available\n",
        "    probs = platt_model.predict_proba(raw_probs.reshape(-1, 1))[:, 1] \\\n",
        "            if platt_model is not None else raw_probs\n",
        "\n",
        "    # Find dataset-specific optimal threshold\n",
        "    ds_threshold = find_optimal_threshold(labels, probs)\n",
        "\n",
        "    m_default = compute_metrics(labels, probs, threshold=0.5)\n",
        "    m_optimal = compute_metrics(labels, probs, threshold=ds_threshold)\n",
        "\n",
        "    print(f\"\\n[{name}]  N={len(labels)}  pos={labels.mean():.1%}\")\n",
        "    print(f\"  @ thresh=0.50 : \" + \"  \".join(f\"{k}={v:.3f}\" for k,v in m_default.items()))\n",
        "    print(f\"  @ thresh={ds_threshold:.2f} : \" + \"  \".join(f\"{k}={v:.3f}\" for k,v in m_optimal.items()))\n",
        "\n",
        "    slug = name.lower()\n",
        "    plot_roc_pr(labels, probs, name, f\"{OUTPUT_DIR}/roc_pr_{slug}.png\")\n",
        "    plot_confusion_matrix(labels, probs, name, f\"{OUTPUT_DIR}/cm_{slug}.png\",\n",
        "                          threshold=ds_threshold)\n",
        "    plot_calibration(labels, probs, name, f\"{OUTPUT_DIR}/calibration_{slug}.png\")\n",
        "    return m_optimal, probs, labels\n",
        "\n",
        "test_results, all_probs, all_labels = {}, {}, {}\n",
        "for Xseq, Xfp, yt, nm in [\n",
        "    (X_seq_t1, X_fp_t1, y_t1, \"Test1\"),\n",
        "    (X_seq_t2, X_fp_t2, y_t2, \"Test2\"),\n",
        "    (X_seq_t3, X_fp_t3, y_t3, \"Test3\"),\n",
        "]:\n",
        "    m, probs, labels = evaluate_test_set(\n",
        "        model, Xseq, Xfp, yt, nm,\n",
        "        opt_threshold=OPT_THRESHOLD_CAL,\n",
        "        platt_model=platt,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    test_results[nm] = m; all_probs[nm] = probs; all_labels[nm] = labels\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "d1d8bc75-00ac-49ff-9ca0-a4d815decbf6",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:37:04.918327Z",
          "iopub.execute_input": "2026-02-25T05:37:04.918872Z",
          "iopub.status.idle": "2026-02-25T05:37:07.786335Z",
          "shell.execute_reply.started": "2026-02-25T05:37:04.918849Z",
          "shell.execute_reply": "2026-02-25T05:37:07.785687Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Â· Chemical Space Visualisation (t-SNE)\n",
        "\n",
        "t-SNE projects the high-dimensional LASSO-selected descriptor matrix into 2D. Colour indicates the binary cardiotoxicity label. Well-separated clusters suggest the descriptors encode meaningful chemistry.\n"
      ],
      "metadata": {
        "id": "b8fde3a2-1781-42b3-a2ff-b7686df8d6e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(X_fp_train, y_train, f\"{OUTPUT_DIR}/tsne_chemical_space.png\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "3e063412-8cad-4078-8208-ffc830d51a9a",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:37:07.787379Z",
          "iopub.execute_input": "2026-02-25T05:37:07.788033Z",
          "iopub.status.idle": "2026-02-25T05:38:20.499624Z",
          "shell.execute_reply.started": "2026-02-25T05:37:07.78801Z",
          "shell.execute_reply": "2026-02-25T05:38:20.498788Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Â· Model Interpretability â€” SHAP Feature Importance\n",
        "\n",
        "We train an **XGBoost** classifier on the same LASSO-selected descriptors and use `shap.TreeExplainer` to compute per-feature SHAP values. The beeswarm plot ranks features by mean absolute SHAP value and shows directional effects (red = high feature value, blue = low).\n"
      ],
      "metadata": {
        "id": "d76cb64b-a29d-4733-b7aa-36185aac6e13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ 1. XGBoost Feature Importance (top 20 by gain) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"Training XGBoost for feature importance...\")\n",
        "xgb_imp = xgb.XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.05,\n",
        "                              random_state=SEED, eval_metric=\"logloss\")\n",
        "xgb_imp.fit(X_fp_train, y_train)\n",
        "\n",
        "imp_df = pd.DataFrame({\n",
        "    \"Feature\"   : sel_feature_names,\n",
        "    \"Importance\": xgb_imp.feature_importances_,\n",
        "}).sort_values(\"Importance\", ascending=False).head(20)\n",
        "\n",
        "# â”€â”€ 2. LASSO coefficient magnitudes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from sklearn.linear_model import Lasso\n",
        "X_tr_sc = np.nan_to_num(fp_scaler.transform(X_fp_train_raw), nan=0, posinf=0, neginf=0)\n",
        "lasso_coef_model = Lasso(alpha=1e-3, max_iter=10000)\n",
        "lasso_coef_model.fit(X_tr_sc, y_train)\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    \"Feature\": [fp_cols[i] for i, m in enumerate(lasso_mask) if m],\n",
        "    \"Coef\"   : np.abs(lasso_coef_model.coef_[lasso_mask]),\n",
        "}).sort_values(\"Coef\", ascending=False).head(20)\n",
        "\n",
        "# â”€â”€ Plot side by side â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "axes[0].barh(imp_df[\"Feature\"][::-1], imp_df[\"Importance\"][::-1], color=\"steelblue\")\n",
        "axes[0].set_xlabel(\"XGBoost Gain Importance\")\n",
        "axes[0].set_title(\"Top 20 Descriptors â€” XGBoost Gain\")\n",
        "axes[0].tick_params(axis=\"y\", labelsize=8)\n",
        "\n",
        "axes[1].barh(coef_df[\"Feature\"][::-1], coef_df[\"Coef\"][::-1], color=\"coral\")\n",
        "axes[1].set_xlabel(\"|LASSO Coefficient|\")\n",
        "axes[1].set_title(\"Top 20 Descriptors â€” LASSO |Coef|\")\n",
        "axes[1].tick_params(axis=\"y\", labelsize=8)\n",
        "\n",
        "plt.suptitle(\"Molecular Descriptor Importance\", fontsize=13, fontweight=\"bold\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/feature_importance.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show(); plt.close()\n",
        "\n",
        "# â”€â”€ Overlap: features both methods agree on â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "overlap = set(imp_df[\"Feature\"]) & set(coef_df[\"Feature\"])\n",
        "print(f\"Top-20 overlap (XGBoost âˆ© LASSO): {len(overlap)}/20\")\n",
        "if overlap:\n",
        "    print(\"  Shared features:\", \", \".join(sorted(overlap)))\n",
        "\n",
        "imp_df.to_csv(f\"{OUTPUT_DIR}/xgb_feature_importance.csv\", index=False)\n",
        "print(\"Feature importance saved.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "31d359e1-3597-4941-a549-2656c110cf21",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:38:20.500614Z",
          "iopub.execute_input": "2026-02-25T05:38:20.500851Z",
          "iopub.status.idle": "2026-02-25T05:38:51.764589Z",
          "shell.execute_reply.started": "2026-02-25T05:38:20.50083Z",
          "shell.execute_reply": "2026-02-25T05:38:51.763849Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15 Â· Baseline Model Comparison\n",
        "\n",
        "We compare the full multi-modal model against four baselines on all three test sets:\n",
        "\n",
        "| Model | Modality | Method |\n",
        "|---|---|---|\n",
        "| **Multimodal** | SMILES + Descriptors | CNN + MLP + Cross-Attention |\n",
        "| **SMILES-only** | SMILES | CNN (FP input zeroed) |\n",
        "| **FP-only** | Descriptors | MLP (SEQ input zeroed) |\n",
        "| **Random Forest** | Descriptors | sklearn RF |\n",
        "| **XGBoost** | Descriptors | XGBoost |\n"
      ],
      "metadata": {
        "id": "b912cfa4-03f0-4095-be8f-01a2fc7835e4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Ablation: SMILES-only (zero FP branch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fp_zeros  = lambda n: np.zeros((n, FP_DIM), dtype=np.float32)\n",
        "seq_zeros = lambda n: np.zeros((n, MAX_LEN), dtype=np.int64)\n",
        "\n",
        "def train_ablation(name, use_seq=True, use_fp=True):\n",
        "    print(f\"\\n[Ablation] {name} ...\")\n",
        "    _seq_tr  = seq_tr  if use_seq else seq_zeros(len(y_tr))\n",
        "    _fp_tr   = fp_tr   if use_fp  else fp_zeros(len(y_tr))\n",
        "    _seq_val = seq_val if use_seq else seq_zeros(len(y_val))\n",
        "    _fp_val  = fp_val  if use_fp  else fp_zeros(len(y_val))\n",
        "\n",
        "    m_abl = MultiModalCardioNet(VOCAB_SIZE, FP_DIM).to(DEVICE)\n",
        "    tr = DataLoader(CardioDataset(_seq_tr, _fp_tr, y_tr),\n",
        "                    batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "    va = DataLoader(CardioDataset(_seq_val, _fp_val, y_val),\n",
        "                    batch_size=BATCH_SIZE)\n",
        "    # Fix: pass y_tr so train_model can compute pos_weight\n",
        "    m_abl, _ = train_model(m_abl, tr, va,\n",
        "                            y_train_arr=y_tr,\n",
        "                            n_epochs=30, patience=5,\n",
        "                            save_path=f\"{OUTPUT_DIR}/{name.lower().replace(' ','_')}.pt\",\n",
        "                            device=DEVICE)\n",
        "    return m_abl\n",
        "\n",
        "model_seq = train_ablation(\"SMILES-only\", use_seq=True,  use_fp=False)\n",
        "model_fp  = train_ablation(\"FP-only\",     use_seq=False, use_fp=True)\n",
        "\n",
        "# â”€â”€ Evaluate ablations on Test1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def ablation_test1(m, use_seq=True, use_fp=True):\n",
        "    Xseq = X_seq_t1 if use_seq else seq_zeros(len(y_t1))\n",
        "    Xfp  = X_fp_t1  if use_fp  else fp_zeros(len(y_t1))\n",
        "    ds   = CardioDataset(Xseq, Xfp, y_t1)\n",
        "    ld   = DataLoader(ds, batch_size=128)\n",
        "    _, _, probs, labels, _, _ = evaluate_loader(m, ld, nn.BCELoss(), DEVICE)\n",
        "    thresh = find_optimal_threshold(labels, probs)\n",
        "    return compute_metrics(labels, probs, threshold=thresh), probs\n",
        "\n",
        "m_seq_t1, probs_seq = ablation_test1(model_seq, use_seq=True,  use_fp=False)\n",
        "m_fp_t1,  probs_fp  = ablation_test1(model_fp,  use_seq=False, use_fp=True)\n",
        "\n",
        "# â”€â”€ RF and XGB on Test1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "rf = RandomForestClassifier(n_estimators=300, random_state=SEED, n_jobs=-1)\n",
        "rf.fit(X_fp_train, y_train)\n",
        "probs_rf = rf.predict_proba(X_fp_t1)[:, 1]\n",
        "thresh_rf = find_optimal_threshold(y_t1, probs_rf)\n",
        "m_rf = compute_metrics(y_t1, probs_rf, threshold=thresh_rf)\n",
        "\n",
        "xgb_base = xgb.XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.05,\n",
        "                               random_state=SEED, eval_metric=\"logloss\")\n",
        "xgb_base.fit(X_fp_train, y_train)\n",
        "probs_xgb = xgb_base.predict_proba(X_fp_t1)[:, 1]\n",
        "thresh_xgb = find_optimal_threshold(y_t1, probs_xgb)\n",
        "m_xgb = compute_metrics(y_t1, probs_xgb, threshold=thresh_xgb)\n",
        "\n",
        "# â”€â”€ Summary table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "comparison = {\n",
        "    \"Model\"   : [\"Multimodal-v2\",\"SMILES-only\",\"FP-only\",\"RandomForest\",\"XGBoost\"],\n",
        "    \"ROC-AUC\" : [test_results[\"Test1\"][\"ROC-AUC\"], m_seq_t1[\"ROC-AUC\"], m_fp_t1[\"ROC-AUC\"],\n",
        "                 m_rf[\"ROC-AUC\"], m_xgb[\"ROC-AUC\"]],\n",
        "    \"F1\"      : [test_results[\"Test1\"][\"F1\"], m_seq_t1[\"F1\"], m_fp_t1[\"F1\"],\n",
        "                 m_rf[\"F1\"], m_xgb[\"F1\"]],\n",
        "    \"MCC\"     : [test_results[\"Test1\"][\"MCC\"], m_seq_t1[\"MCC\"], m_fp_t1[\"MCC\"],\n",
        "                 m_rf[\"MCC\"], m_xgb[\"MCC\"]],\n",
        "}\n",
        "comp_df = pd.DataFrame(comparison)\n",
        "display(comp_df.round(4))\n",
        "comp_df.to_csv(f\"{OUTPUT_DIR}/model_comparison.csv\", index=False)\n",
        "plot_model_comparison(comparison, f\"{OUTPUT_DIR}/model_comparison.png\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "47063514-3a98-4f8c-a8fe-5fd75d69fa12",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:38:51.765564Z",
          "iopub.execute_input": "2026-02-25T05:38:51.765834Z",
          "iopub.status.idle": "2026-02-25T05:41:18.67553Z",
          "shell.execute_reply.started": "2026-02-25T05:38:51.765813Z",
          "shell.execute_reply": "2026-02-25T05:41:18.674843Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15b Â· Four Fusion Mechanism Comparison\n",
        "\n",
        "We train all four fusion variants from Â§6 on the same data splits and compare them across all three external test sets:\n",
        "\n",
        "| Mechanism | Cross-Attention | Gating | Key Property |\n",
        "|---|---|---|---|\n",
        "| **Concatenation** | âŒ | âŒ | Baseline â€” both features present but no interaction |\n",
        "| **Attention-Only** | âœ… | âŒ | Cross-modal interaction, equal weighting |\n",
        "| **Gate-Only** | âŒ | âœ… | Adaptive weighting, no cross-modal interaction |\n",
        "| **Gated-Attention** | âœ… | âœ… | Full model â€” interaction + adaptive weighting |"
      ],
      "metadata": {
        "id": "N8QQ-HIXhi71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Â§6 â€” Four Fusion Variants  (FIXED: multi-token attention)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# â”€â”€ Shared constant â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "N_TOKENS   = 8    # number of tokens each 128-d vector is split into\n",
        "TOKEN_DIM  = 16   # 128 / N_TOKENS  (must divide evenly)\n",
        "# With N_TOKENS=8 keys, softmax can assign 0.125â€“1.0 per token.\n",
        "# Previously N_TOKENS=1  â†’ softmax(scalar) = 1.0 always â†’ flat bars in graph.\n",
        "\n",
        "\n",
        "class SequenceBranch(nn.Module):\n",
        "    \"\"\"SMILES â†’ Embedding â†’ Conv1D Ã—2 â†’ AdaptiveMaxPool â†’ FC(128) + LayerNorm\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=64, conv_channels=128, kernel_size=5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n",
        "        self.conv1   = nn.Conv1d(embed_dim, conv_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.conv2   = nn.Conv1d(conv_channels, conv_channels, kernel_size=3, padding=1)\n",
        "        self.pool    = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc      = nn.Linear(conv_channels, 128)\n",
        "        self.norm    = nn.LayerNorm(128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.embedding(x).permute(0, 2, 1)\n",
        "        e = F.relu(self.conv1(e))\n",
        "        e = F.relu(self.conv2(e))\n",
        "        e = self.pool(e).squeeze(2)\n",
        "        e = self.dropout(e)\n",
        "        return self.norm(F.relu(self.fc(e)))\n",
        "\n",
        "\n",
        "class FingerprintBranch(nn.Module):\n",
        "    \"\"\"Descriptor â†’ FC(512) â†’ FC(256) â†’ FC(128) + residual skip + LayerNorm\"\"\"\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.fc1     = nn.Linear(in_dim, 512)\n",
        "        self.bn1     = nn.BatchNorm1d(512)\n",
        "        self.fc2     = nn.Linear(512, 256)\n",
        "        self.bn2     = nn.BatchNorm1d(256)\n",
        "        self.fc3     = nn.Linear(256, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.norm    = nn.LayerNorm(128)\n",
        "        self.skip    = nn.Linear(in_dim, 128, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.skip(x)\n",
        "        x = self.bn1(F.relu(self.fc1(x))); x = self.dropout(x)\n",
        "        x = self.bn2(F.relu(self.fc2(x))); x = self.dropout(x)\n",
        "        return self.norm(F.relu(self.fc3(x) + residual))\n",
        "\n",
        "\n",
        "def to_tokens(x, n_tokens=N_TOKENS, token_dim=TOKEN_DIM):\n",
        "    \"\"\"\n",
        "    Reshape a (B, 128) vector into (B, n_tokens, token_dim) token sequence.\n",
        "\n",
        "    WHY THIS FIXES UNIFORM ATTENTION:\n",
        "      Before: unsqueeze(1) â†’ (B, 1, 128) â€” 1 key â†’ softmax(1 scalar) = 1.0 always\n",
        "      After:  reshape      â†’ (B, 8, 16)  â€” 8 keys â†’ softmax learns non-uniform dist.\n",
        "\n",
        "    No parameters needed â€” just a reshape. The 128-d embedding naturally\n",
        "    decomposes into 8 sub-spaces of 16 dims each, one per token position.\n",
        "    \"\"\"\n",
        "    B = x.size(0)\n",
        "    return x.view(B, n_tokens, token_dim)   # (B, 8, 16)\n",
        "\n",
        "\n",
        "def from_tokens(x_tok):\n",
        "    \"\"\"\n",
        "    Collapse attended token sequence (B, n_tokens, token_dim) back to (B, 128).\n",
        "    Uses flatten (not mean-pool):\n",
        "      mean(dim=1) on (B,8,16) -> (B,16)  [WRONG]\n",
        "      flatten(1)  on (B,8,16) -> (B,128) [CORRECT]\n",
        "    \"\"\"\n",
        "    return x_tok.flatten(start_dim=1)   # (B, 8*16) = (B, 128)\n",
        "\n",
        "\n",
        "# â”€â”€ Fusion 1: Direct Concatenation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class ConcatFusionNet(nn.Module):\n",
        "    \"\"\"Concat [f_s ; f_f] â†’ Linear(256,128) â€” no cross-modal interaction.\"\"\"\n",
        "    def __init__(self, vocab_size, fp_dim, embed_dim=64, conv_ch=128, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.seq_branch = SequenceBranch(vocab_size, embed_dim, conv_ch)\n",
        "        self.fp_branch  = FingerprintBranch(fp_dim)\n",
        "        self.fusion     = nn.Sequential(\n",
        "            nn.Linear(256, 128), nn.ReLU(), nn.LayerNorm(128), nn.Dropout(0.3)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),  nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(32, 1),   nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, seq, fp):\n",
        "        f_s = self.seq_branch(seq)\n",
        "        f_f = self.fp_branch(fp)\n",
        "        fused = self.fusion(torch.cat([f_s, f_f], dim=1))\n",
        "        out = self.classifier(fused).squeeze(1)\n",
        "        g_s = torch.full((seq.size(0),), 0.5, device=seq.device)\n",
        "        g_f = torch.full((fp.size(0),),  0.5, device=fp.device)\n",
        "        return out, (g_s, g_f)\n",
        "\n",
        "\n",
        "# â”€â”€ Fusion 2: Attention-Only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class AttentionFusionNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Cross-attention with multi-token decomposition.\n",
        "\n",
        "    FIX: Each 128-d branch vector is reshaped to (B, 8, 16) before attention.\n",
        "    Softmax now operates over 8 keys per query token, producing a genuine\n",
        "    non-uniform distribution that can differ by compound and label.\n",
        "\n",
        "    TOKEN_DIM=16 requires n_heads to divide 16 evenly â†’ use n_heads=4 (16/4=4).\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, fp_dim, embed_dim=64, conv_ch=128, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.seq_branch  = SequenceBranch(vocab_size, embed_dim, conv_ch)\n",
        "        self.fp_branch   = FingerprintBranch(fp_dim)\n",
        "        # Separate modules, token_dim=16, n_heads=4 (head_dim=4, valid)\n",
        "        self.attn_s2f    = nn.MultiheadAttention(TOKEN_DIM, n_heads, batch_first=True, dropout=0.1)\n",
        "        self.attn_f2s    = nn.MultiheadAttention(TOKEN_DIM, n_heads, batch_first=True, dropout=0.1)\n",
        "        # Gate on raw features (128+128=256 â†’ 2)\n",
        "        self.branch_gate = nn.Linear(256, 2)\n",
        "        self.classifier  = nn.Sequential(\n",
        "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),  nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(32, 1),   nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, seq, fp):\n",
        "        f_s = self.seq_branch(seq)   # (B, 128)\n",
        "        f_f = self.fp_branch(fp)     # (B, 128)\n",
        "\n",
        "        # â”€â”€ Multi-token cross-attention â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        # FIX: reshape to (B, N_TOKENS, TOKEN_DIM) so softmax is meaningful\n",
        "        s_tok = to_tokens(f_s)   # (B, 8, 16)\n",
        "        f_tok = to_tokens(f_f)   # (B, 8, 16)\n",
        "\n",
        "        s_att_tok, _ = self.attn_s2f(s_tok, f_tok, f_tok)  # SMILES queries FP\n",
        "        f_att_tok, _ = self.attn_f2s(f_tok, s_tok, s_tok)  # FP queries SMILES\n",
        "\n",
        "        f_s_att = from_tokens(s_att_tok)  # (B, 128)\n",
        "        f_f_att = from_tokens(f_att_tok)  # (B, 128)\n",
        "\n",
        "        # Gate on RAW features â€” genuinely different signal per branch\n",
        "        gate = torch.softmax(self.branch_gate(torch.cat([f_s, f_f], dim=1)), dim=1)\n",
        "        g_s, g_f = gate[:, 0:1], gate[:, 1:2]\n",
        "\n",
        "        fused = g_s * f_s_att + g_f * f_f_att\n",
        "        out = self.classifier(fused).squeeze(1)\n",
        "        return out, (g_s.squeeze(1), g_f.squeeze(1))\n",
        "\n",
        "\n",
        "# â”€â”€ Fusion 3: Gate-Only (no attention) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class GateFusionNet(nn.Module):\n",
        "    \"\"\"Softmax gating: g_sÂ·f_s + g_fÂ·f_f â€” weighted blend without cross-attention.\"\"\"\n",
        "    def __init__(self, vocab_size, fp_dim, embed_dim=64, conv_ch=128, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.seq_branch = SequenceBranch(vocab_size, embed_dim, conv_ch)\n",
        "        self.fp_branch  = FingerprintBranch(fp_dim)\n",
        "        self.gate_fc    = nn.Linear(256, 2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),  nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(32, 1),   nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, seq, fp):\n",
        "        f_s = self.seq_branch(seq)\n",
        "        f_f = self.fp_branch(fp)\n",
        "        g = torch.softmax(self.gate_fc(torch.cat([f_s, f_f], dim=1)), dim=1)\n",
        "        g_s, g_f = g[:, 0:1], g[:, 1:2]\n",
        "        fused = g_s * f_s + g_f * f_f\n",
        "        out = self.classifier(fused).squeeze(1)\n",
        "        return out, (g_s.squeeze(1), g_f.squeeze(1))\n",
        "\n",
        "\n",
        "# â”€â”€ Fusion 4: Gated-Attention (full model) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class MultiModalCardioNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Gated cross-attention fusion with multi-token decomposition.\n",
        "\n",
        "    FIX applied (same as AttentionFusionNet):\n",
        "      Each 128-d vector â†’ (B, 8, 16) tokens before attention.\n",
        "      Softmax now over 8 keys â†’ non-uniform, compound-specific weights.\n",
        "      Attention heatmap will show meaningful variation across samples/labels.\n",
        "\n",
        "    Architecture otherwise unchanged:\n",
        "      - Separate attn_s2f / attn_f2s (asymmetric, no weight sharing)\n",
        "      - Richer gate: raw + attention residuals (512â†’128â†’2)\n",
        "      - Residual raw_proj skip connection\n",
        "      - Deeper classifier\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, fp_dim, embed_dim=64, conv_ch=128, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.seq_branch  = SequenceBranch(vocab_size, embed_dim, conv_ch)\n",
        "        self.fp_branch   = FingerprintBranch(fp_dim)\n",
        "        # Multi-token attention: TOKEN_DIM=16, n_heads=4\n",
        "        self.attn_s2f    = nn.MultiheadAttention(TOKEN_DIM, n_heads, batch_first=True, dropout=0.1)\n",
        "        self.attn_f2s    = nn.MultiheadAttention(TOKEN_DIM, n_heads, batch_first=True, dropout=0.1)\n",
        "        # Richer gate: raw (256) + attention residuals (256) = 512 â†’ 128 â†’ 2\n",
        "        self.gate_fc     = nn.Sequential(\n",
        "            nn.Linear(512, 128), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "        self.raw_proj    = nn.Sequential(nn.Linear(256, 128), nn.ReLU(), nn.LayerNorm(128))\n",
        "        self.blend_norm  = nn.LayerNorm(128)\n",
        "        self.classifier  = nn.Sequential(\n",
        "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),  nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(32, 16),  nn.ReLU(), nn.Dropout(0.1),\n",
        "            nn.Linear(16, 1),   nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, seq, fp):\n",
        "        f_s = self.seq_branch(seq)   # (B, 128)\n",
        "        f_f = self.fp_branch(fp)     # (B, 128)\n",
        "\n",
        "        # â”€â”€ Multi-token cross-attention â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        s_tok = to_tokens(f_s)   # (B, 8, 16)\n",
        "        f_tok = to_tokens(f_f)   # (B, 8, 16)\n",
        "\n",
        "        s_att_tok, _ = self.attn_s2f(s_tok, f_tok, f_tok)\n",
        "        f_att_tok, _ = self.attn_f2s(f_tok, s_tok, s_tok)\n",
        "\n",
        "        f_s_att = from_tokens(s_att_tok)   # (B, 128)\n",
        "        f_f_att = from_tokens(f_att_tok)   # (B, 128)\n",
        "\n",
        "        # Attention residuals\n",
        "        delta_s = f_s_att - f_s    # (B, 128)\n",
        "        delta_f = f_f_att - f_f    # (B, 128)\n",
        "\n",
        "        # Richer gate input\n",
        "        gate_input  = torch.cat([f_s, f_f, delta_s, delta_f], dim=1)   # (B, 512)\n",
        "        gate        = torch.softmax(self.gate_fc(gate_input), dim=1)    # (B, 2)\n",
        "        g_s, g_f    = gate[:, 0:1], gate[:, 1:2]\n",
        "\n",
        "        gated_blend = g_s * f_s_att + g_f * f_f_att\n",
        "        raw_res     = self.raw_proj(torch.cat([f_s, f_f], dim=1))\n",
        "        fused       = self.blend_norm(gated_blend + raw_res)\n",
        "\n",
        "        out = self.classifier(fused).squeeze(1)\n",
        "        return out, (g_s.squeeze(1), g_f.squeeze(1))\n",
        "\n",
        "\n",
        "# â”€â”€ Sanity checks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "_s_dummy = torch.zeros(4, MAX_LEN, dtype=torch.long).to(DEVICE)\n",
        "_f_dummy = torch.zeros(4, FP_DIM,  dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "for _cls, _name in [\n",
        "    (ConcatFusionNet,     \"ConcatFusionNet\"),\n",
        "    (AttentionFusionNet,  \"AttentionFusionNet\"),\n",
        "    (GateFusionNet,       \"GateFusionNet\"),\n",
        "    (MultiModalCardioNet, \"MultiModalCardioNet\"),\n",
        "]:\n",
        "    _m = _cls(VOCAB_SIZE, FP_DIM, n_heads=N_HEADS).to(DEVICE)\n",
        "    _out, (_gs, _gf) = _m(_s_dummy, _f_dummy)\n",
        "    assert _out.shape == (4,), f\"{_name}: expected (4,), got {_out.shape}\"\n",
        "    _n = sum(p.numel() for p in _m.parameters() if p.requires_grad)\n",
        "    print(f\"  [OK] {_name:<26} output={_out.shape}  \"\n",
        "          f\"gate_s={_gs.mean():.3f}  gate_f={_gf.mean():.3f}  params={_n:,}\")\n",
        "\n",
        "print(\"\\n[SANITY] All 4 fusion models pass shape checks.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:41:18.67667Z",
          "iopub.execute_input": "2026-02-25T05:41:18.676925Z",
          "iopub.status.idle": "2026-02-25T05:41:18.759943Z",
          "shell.execute_reply.started": "2026-02-25T05:41:18.676903Z",
          "shell.execute_reply": "2026-02-25T05:41:18.759294Z"
        },
        "id": "OMu_7FEThi71"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# Â§15b â€” Four Fusion Mechanisms Comparison (execution)\n",
        "# =================================================================\n",
        "\n",
        "def train_fusion_variant(fusion_cls, name):\n",
        "    \"\"\"\n",
        "    Train one fusion variant and evaluate on all three external test sets.\n",
        "    All variants use identical budget: n_epochs=60, patience=10.\n",
        "    MultiModalCardioNet uses its specialised trainer (focal loss + warmup).\n",
        "    \"\"\"\n",
        "    print(f'\\n[Fusion] Training: {name}  (n_epochs=60, patience=10)')\n",
        "    m = fusion_cls(VOCAB_SIZE, FP_DIM, n_heads=N_HEADS).to(DEVICE)\n",
        "    save_path = f\"{OUTPUT_DIR}/fusion_{name.lower().replace(' ','_')}.pt\"\n",
        "\n",
        "    if fusion_cls is MultiModalCardioNet:\n",
        "        m, _ = train_gated_attention(\n",
        "            m, tr_ld, val_ld, y_train_arr=y_tr,\n",
        "            n_epochs=60, patience=10,\n",
        "            save_path=save_path, device=DEVICE\n",
        "        )\n",
        "    else:\n",
        "        m, _ = train_model(\n",
        "            m, tr_ld, val_ld, y_train_arr=y_tr,\n",
        "            n_epochs=60, patience=10,\n",
        "            save_path=save_path, device=DEVICE\n",
        "        )\n",
        "\n",
        "    results = {}\n",
        "    for Xseq, Xfp, yt, nm in [\n",
        "        (X_seq_t1, X_fp_t1, y_t1, 'Test1'),\n",
        "        (X_seq_t2, X_fp_t2, y_t2, 'Test2'),\n",
        "        (X_seq_t3, X_fp_t3, y_t3, 'Test3'),\n",
        "    ]:\n",
        "        ds = CardioDataset(Xseq, Xfp, yt)\n",
        "        ld = DataLoader(ds, batch_size=128)\n",
        "        _, _, probs, labels, _, _ = evaluate_loader(m, ld, nn.BCELoss(), DEVICE)\n",
        "        thresh = find_optimal_threshold(labels, probs)\n",
        "        results[nm] = compute_metrics(labels, probs, threshold=thresh)\n",
        "    return results\n",
        "\n",
        "\n",
        "print('Training all 4 fusion variants (this takes several minutes)...')\n",
        "fusion_results = {}\n",
        "for cls, name in [\n",
        "    (ConcatFusionNet,     'Concatenation'),\n",
        "    (AttentionFusionNet,  'Attention-Only'),\n",
        "    (GateFusionNet,       'Gate-Only'),\n",
        "    (MultiModalCardioNet, 'Gated-Attention'),\n",
        "]:\n",
        "    fusion_results[name] = train_fusion_variant(cls, name)\n",
        "\n",
        "\n",
        "# -- Build comparison table --\n",
        "def build_fusion_table(fusion_results):\n",
        "    rows = []\n",
        "    for fusion_name, test_dict in fusion_results.items():\n",
        "        for test_set, metrics in test_dict.items():\n",
        "            row = {'Fusion': fusion_name, 'Test Set': test_set}\n",
        "            row.update(metrics)\n",
        "            rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "fusion_df = build_fusion_table(fusion_results)\n",
        "fusion_df.to_csv(f\"{OUTPUT_DIR}/fusion_comparison.csv\", index=False)\n",
        "print('\\n' + '='*70)\n",
        "print('FUSION MECHANISM COMPARISON TABLE')\n",
        "print('='*70)\n",
        "display(fusion_df.pivot_table(\n",
        "    index='Fusion', columns='Test Set',\n",
        "    values=['ROC-AUC','AUPR','F1','MCC'],\n",
        "    aggfunc='first'\n",
        ").round(4))\n",
        "\n",
        "\n",
        "# -- Visualise fusion comparison --\n",
        "def plot_fusion_comparison(fusion_results, save_path):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    fusion_names = list(fusion_results.keys())\n",
        "    test_sets    = ['Test1', 'Test2', 'Test3']\n",
        "    colors       = ['#4C72B0', '#55A868', '#C44E52']\n",
        "    x = np.arange(len(fusion_names)); width = 0.25\n",
        "    for metric_idx, (metric, ax) in enumerate(zip(['ROC-AUC', 'AUPR'], axes)):\n",
        "        for j, (ts, color) in enumerate(zip(test_sets, colors)):\n",
        "            vals = [fusion_results[fn].get(ts, {}).get(metric, 0) for fn in fusion_names]\n",
        "            bars = ax.bar(x + j*width, vals, width, label=ts, color=color, alpha=0.85)\n",
        "            for bar, v in zip(bars, vals):\n",
        "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
        "                        f'{v:.3f}', ha='center', va='bottom', fontsize=7, rotation=45)\n",
        "        ax.set_xticks(x + width); ax.set_xticklabels(fusion_names, fontsize=10, rotation=15)\n",
        "        ax.set_ylabel(metric); ax.set_ylim(0, 1.1)\n",
        "        ax.set_title(f'{metric} by Fusion Mechanism')\n",
        "        ax.legend(); ax.grid(axis='y', alpha=0.3)\n",
        "    plt.suptitle('Four Fusion Mechanisms â€” Test Set Comparison', fontsize=13, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.show(); plt.close()\n",
        "    print(f'Fusion comparison plot saved: {save_path}')\n",
        "\n",
        "plot_fusion_comparison(fusion_results, f\"{OUTPUT_DIR}/fusion_comparison.png\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T05:41:18.760954Z",
          "iopub.execute_input": "2026-02-25T05:41:18.761198Z",
          "iopub.status.idle": "2026-02-25T05:45:28.264742Z",
          "shell.execute_reply.started": "2026-02-25T05:41:18.761179Z",
          "shell.execute_reply": "2026-02-25T05:45:28.264042Z"
        },
        "id": "O7nh6GZ_hi79"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 16 Â· Statistical Significance â€” DeLong AUC Test\n",
        "\n",
        "The **DeLong test** is a non-parametric method to assess whether the difference in ROC-AUC between two models is statistically significant. We compare the full multi-modal model against the FP-only baseline on Test1.\n",
        "\n",
        "A p-value < 0.05 indicates a statistically significant improvement.\n"
      ],
      "metadata": {
        "id": "7e523868-f31a-4b07-96ec-9b33de284631"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def delong_test(y_true, prob1, prob2):\n",
        "    \"\"\"\n",
        "    DeLong z-statistic: compares two correlated AUCs on the same test set.\n",
        "    Uses structural components method (Sun & Xu 2014).\n",
        "    \"\"\"\n",
        "    def _auc_and_var(gt, preds):\n",
        "        pos = preds[gt == 1]; neg = preds[gt == 0]\n",
        "        n1, n0 = len(pos), len(neg)\n",
        "        auc_val = np.mean([np.mean(p > neg) + 0.5 * np.mean(p == neg) for p in pos])\n",
        "        v10 = np.array([np.mean(p > neg) + 0.5 * np.mean(p == neg) for p in pos])\n",
        "        v01 = np.array([np.mean(n < pos) + 0.5 * np.mean(n == pos) for n in neg])\n",
        "        var = np.var(v10) / n1 + np.var(v01) / n0\n",
        "        return auc_val, var\n",
        "\n",
        "    auc1, var1 = _auc_and_var(y_true, prob1)\n",
        "    auc2, var2 = _auc_and_var(y_true, prob2)\n",
        "    z = (auc1 - auc2) / np.sqrt(var1 + var2 + 1e-12)\n",
        "    p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
        "    return auc1, auc2, z, p\n",
        "\n",
        "# Guard: probs_fp is defined by the ablation cell above\n",
        "# FIX BUG 13: dir() lists object attributes, not scope variables. Use vars() instead.\n",
        "if 'probs_fp' not in vars():\n",
        "    raise RuntimeError(\"Run the Baseline Comparison cell first â€” probs_fp is not yet defined.\")\n",
        "\n",
        "y_t1_int = y_t1.astype(int)\n",
        "auc1, auc2, z, p = delong_test(y_t1_int, all_probs[\"Test1\"], probs_fp)\n",
        "\n",
        "print(\"DeLong AUC Comparison: Multimodal-v2 vs FP-only (Test1)\")\n",
        "print(f\"  Multimodal AUC : {auc1:.4f}\")\n",
        "print(f\"  FP-only AUC   : {auc2:.4f}\")\n",
        "print(f\"  Î” AUC          : {auc1 - auc2:+.4f}\")\n",
        "print(f\"  z-score        : {z:.3f}\")\n",
        "print(f\"  p-value        : {p:.4f}  {'âœ“ significant' if p < 0.05 else 'âœ— not significant'} (Î±=0.05)\")\n",
        "print()\n",
        "# Also compare vs SMILES-only\n",
        "auc1b, auc2b, z2, p2 = delong_test(y_t1_int, all_probs[\"Test1\"], probs_seq)\n",
        "print(\"DeLong AUC Comparison: Multimodal-v2 vs SMILES-only (Test1)\")\n",
        "print(f\"  Multimodal AUC  : {auc1b:.4f}\")\n",
        "print(f\"  SMILES-only AUC : {auc2b:.4f}\")\n",
        "print(f\"  Î” AUC           : {auc1b - auc2b:+.4f}\")\n",
        "print(f\"  z-score         : {z2:.3f}\")\n",
        "print(f\"  p-value         : {p2:.4f}  {'âœ“ significant' if p2 < 0.05 else 'âœ— not significant'} (Î±=0.05)\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "7593cf96-6970-45ce-b919-2a54093467a5",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:45:28.265689Z",
          "iopub.execute_input": "2026-02-25T05:45:28.265914Z",
          "iopub.status.idle": "2026-02-25T05:45:28.279746Z",
          "shell.execute_reply.started": "2026-02-25T05:45:28.265894Z",
          "shell.execute_reply": "2026-02-25T05:45:28.279083Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17 Â· Final Results Summary & Improvement Analysis\n"
      ],
      "metadata": {
        "id": "0524536e-b2b9-423e-8397-066d32b3d721"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Results table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "rows = []\n",
        "for nm, m in test_results.items():\n",
        "    row = {\"Dataset\": nm, \"Model\": \"Multimodal-v2\"}\n",
        "    row.update(m); rows.append(row)\n",
        "\n",
        "summary_df = pd.DataFrame(rows)\n",
        "summary_df.to_csv(f\"{OUTPUT_DIR}/final_results.csv\", index=False)\n",
        "print(\"External Test Set Performance â€” Improved Multimodal Model\")\n",
        "display(summary_df.round(4))\n",
        "\n",
        "# â”€â”€ v1 baseline for comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "v1_results = {\n",
        "    \"Test1\": {\"ROC-AUC\": 0.733, \"F1\": 0.514, \"ACC\": 0.585, \"MCC\": 0.286, \"AUPR\": 0.475},\n",
        "    \"Test2\": {\"ROC-AUC\": 0.786, \"F1\": 0.188, \"ACC\": 0.661, \"MCC\": 0.219, \"AUPR\": 0.190},\n",
        "    \"Test3\": {\"ROC-AUC\": 0.817, \"F1\": 0.808, \"ACC\": 0.773, \"MCC\": 0.586, \"AUPR\": 0.916},\n",
        "}\n",
        "print(\"\\nDelta vs v1 (positive = improvement):\")\n",
        "for nm in [\"Test1\", \"Test2\", \"Test3\"]:\n",
        "    v1 = v1_results[nm]; v2 = test_results.get(nm, {})\n",
        "    deltas = {k: v2.get(k, 0) - v1.get(k, 0) for k in v1}\n",
        "    delta_str = \"  \".join(f\"{k}: {v:+.3f}\" for k, v in deltas.items())\n",
        "    print(f\"  [{nm}] {delta_str}\")\n",
        "\n",
        "# â”€â”€ Save all outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import pickle, shutil\n",
        "with open(f\"{OUTPUT_DIR}/smiles_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "with open(f\"{OUTPUT_DIR}/platt_scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(platt, f)\n",
        "\n",
        "print(f\"\\nAll outputs saved to '{OUTPUT_DIR}/':\")\n",
        "for fn in sorted(os.listdir(OUTPUT_DIR)):\n",
        "    size = os.path.getsize(f\"{OUTPUT_DIR}/{fn}\")\n",
        "    print(f\"  {fn:<48} {size/1024:>7.1f} KB\")\n",
        "\n",
        "shutil.make_archive(f\"{OUTPUT_DIR}/../cardiotox_v2_outputs\", \"zip\", OUTPUT_DIR)\n",
        "print(\"\\nZipped: cardiotox_v2_outputs.zip\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "1b83290d-e185-49c6-843f-55031aee3d73",
        "execution": {
          "iopub.status.busy": "2026-02-25T05:45:28.280641Z",
          "iopub.execute_input": "2026-02-25T05:45:28.280888Z",
          "iopub.status.idle": "2026-02-25T05:45:30.607889Z",
          "shell.execute_reply.started": "2026-02-25T05:45:28.280867Z",
          "shell.execute_reply": "2026-02-25T05:45:30.607248Z"
        }
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}